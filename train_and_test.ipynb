{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high0</th>\n",
       "      <th>high1</th>\n",
       "      <th>high2</th>\n",
       "      <th>high3</th>\n",
       "      <th>high4</th>\n",
       "      <th>high5</th>\n",
       "      <th>high6</th>\n",
       "      <th>high7</th>\n",
       "      <th>high8</th>\n",
       "      <th>high9</th>\n",
       "      <th>...</th>\n",
       "      <th>low694</th>\n",
       "      <th>low695</th>\n",
       "      <th>low696</th>\n",
       "      <th>low697</th>\n",
       "      <th>low698</th>\n",
       "      <th>low699</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.359752</td>\n",
       "      <td>0.424275</td>\n",
       "      <td>-0.681706</td>\n",
       "      <td>0.433839</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>97.547158</td>\n",
       "      <td>48.476906</td>\n",
       "      <td>...</td>\n",
       "      <td>147867.681361</td>\n",
       "      <td>34273.003529</td>\n",
       "      <td>147552.433395</td>\n",
       "      <td>33959.200637</td>\n",
       "      <td>39.083400</td>\n",
       "      <td>10.692026</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.374953</td>\n",
       "      <td>0.477638</td>\n",
       "      <td>-0.666732</td>\n",
       "      <td>0.429372</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>94.752225</td>\n",
       "      <td>45.264284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.121715</td>\n",
       "      <td>3.024193</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.374791</td>\n",
       "      <td>0.433773</td>\n",
       "      <td>-0.650851</td>\n",
       "      <td>0.302914</td>\n",
       "      <td>0.027013</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.027013</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>103.646422</td>\n",
       "      <td>66.342239</td>\n",
       "      <td>...</td>\n",
       "      <td>309465.762848</td>\n",
       "      <td>70251.212387</td>\n",
       "      <td>86736.061773</td>\n",
       "      <td>19023.865616</td>\n",
       "      <td>272.618048</td>\n",
       "      <td>39.410815</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.425997</td>\n",
       "      <td>0.407457</td>\n",
       "      <td>-0.651442</td>\n",
       "      <td>0.335262</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>107.650662</td>\n",
       "      <td>116.364404</td>\n",
       "      <td>...</td>\n",
       "      <td>34427.765392</td>\n",
       "      <td>8119.821369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>243362.224842</td>\n",
       "      <td>54139.263203</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.462599</td>\n",
       "      <td>0.428727</td>\n",
       "      <td>-0.676588</td>\n",
       "      <td>0.425349</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>104.963457</td>\n",
       "      <td>19.671929</td>\n",
       "      <td>...</td>\n",
       "      <td>516165.111104</td>\n",
       "      <td>112837.709221</td>\n",
       "      <td>355822.121392</td>\n",
       "      <td>80991.490121</td>\n",
       "      <td>142600.840444</td>\n",
       "      <td>31689.816294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      high0     high1     high2     high3     high4     high5     high6   \n",
       "0  0.359752  0.424275 -0.681706  0.433839  0.004776  0.001909  0.004776  \\\n",
       "1  0.374953  0.477638 -0.666732  0.429372  0.010201  0.002640  0.010201   \n",
       "2  0.374791  0.433773 -0.650851  0.302914  0.027013  0.007587  0.027013   \n",
       "3  0.425997  0.407457 -0.651442  0.335262  0.018433  0.004401  0.018433   \n",
       "4  0.462599  0.428727 -0.676588  0.425349  0.004667  0.002822  0.004667   \n",
       "\n",
       "      high7       high8       high9  ...         low694         low695   \n",
       "0  0.001909   97.547158   48.476906  ...  147867.681361   34273.003529  \\\n",
       "1  0.002640   94.752225   45.264284  ...       0.000000       0.000000   \n",
       "2  0.007587  103.646422   66.342239  ...  309465.762848   70251.212387   \n",
       "3  0.004401  107.650662  116.364404  ...   34427.765392    8119.821369   \n",
       "4  0.002822  104.963457   19.671929  ...  516165.111104  112837.709221   \n",
       "\n",
       "          low696        low697         low698        low699  y1  y2  y3  y4  \n",
       "0  147552.433395  33959.200637      39.083400     10.692026   2   1   0   6  \n",
       "1       0.000000      0.000000       9.121715      3.024193   2   1   0   6  \n",
       "2   86736.061773  19023.865616     272.618048     39.410815   0   1   0   4  \n",
       "3       0.000000      0.000000  243362.224842  54139.263203   2   1   0   4  \n",
       "4  355822.121392  80991.490121  142600.840444  31689.816294   0   1   0   4  \n",
       "\n",
       "[5 rows x 1450 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['y1','y2','y3','y4'],axis=1)\n",
    "y1 = data['y1']\n",
    "y2 = data['y2']\n",
    "y3 = data['y3']\n",
    "y4 = data['y4']\n",
    "y = data[['y1','y2','y3','y4']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查 nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1564])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(np.isnan(X).any(axis=1)==True)[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop 1 rows with nan value\n"
     ]
    }
   ],
   "source": [
    "if len(idx) != 0:\n",
    "    print(f\"drop {len(idx)} rows with nan value\")\n",
    "    for i in idx:\n",
    "        X = np.delete(X, i, axis=0)\n",
    "        y1 = np.delete(y1, i, axis=0)\n",
    "        y2 = np.delete(y2, i, axis=0)\n",
    "        y3 = np.delete(y3, i, axis=0)\n",
    "        y4 = np.delete(y4, i, axis=0)\n",
    "        y = np.delete(y, i, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=0, arr=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nan in X_norm\n",
    "np.where(np.isnan(X_norm).any(axis=1)==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in videos y:3655\n"
     ]
    }
   ],
   "source": [
    "print(f\"Read in videos y:{len(y1)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:1446\n"
     ]
    }
   ],
   "source": [
    "print(f\"X:{len(X[0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video num: X_train:2924, X_test:731, y_train:2924, y_test:731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# frame split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, random_state=42)\n",
    "print(f\"Video num: X_train:{len(X_train)}, X_test:{len(X_test)}, y_train:{len(y_train)}, y_test:{len(y_test)}\")\n",
    "\n",
    "y1_train, y1_test = y_train[:,0], y_test[:,0]\n",
    "y2_train, y2_test = y_train[:,1], y_test[:,1]\n",
    "y3_train, y3_test = y_train[:,2], y_test[:,2]\n",
    "y4_train, y4_test = y_train[:,3], y_test[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"], \n",
    "        ['中性','积极','消极'], \n",
    "        [\"专注（任务中）\",\"走神（任务外）\"], \n",
    "        [\"玩乐\", \"闲聊\", \"一人独立尝试一人摸鱼\", \"各自神游\", \"主导\", \"支持\", \"旁观\", \"冲突\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties  # 步骤一\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"]=[\"AR PL UMing CN\"] #设置字体\n",
    "plt.rcParams[\"axes.unicode_minus\"]=False #该语句解决图像中的“-”负号的乱码问题\n",
    "\n",
    "def num_of_cls(y, target): \n",
    "    N = []\n",
    "    for i in range(len(target)):\n",
    "        print(target[i] + f\":{len(y[y==i])}\", end=\", \")\n",
    "        N.append(len(y[y==i]))\n",
    "    print()\n",
    "    return N\n",
    "\n",
    "for i in range(4):\n",
    "    N = num_of_cls(y[:,i],target[i])\n",
    "    # proportions = [ p/len(y) for p in N]\n",
    "    plt.pie(N,labels=target[i],autopct='%1.1f%%')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inversely proportional class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = [class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(i), y=i) for i in [y1,y2,y3,y4]]\n",
    "\n",
    "\n",
    "# Convert class weights to a dictionary for compatibility with some classifiers\n",
    "class_weight_dict = [dict(enumerate(class_weights[i])) for i in range(4)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation  \n",
    "- 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "\n",
    "def crossVal(rfc, X, y):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scoring = ['accuracy', 'f1_weighted', 'recall_weighted', 'precision_weighted']\n",
    "\n",
    "    # 使用交叉验证器对模型进行评估\n",
    "    scores = cross_validate(rfc, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "    # 输出交叉验证结果\n",
    "    print('Accuracy:', scores['test_accuracy'].mean())\n",
    "    print('F1 score:', scores['test_f1_weighted'].mean())\n",
    "    print('Recall:', scores['test_recall_weighted'].mean())\n",
    "    print('Precision:', scores['test_precision_weighted'].mean())\n",
    "\n",
    "def GridSearch(estimator, param_grid, X_train, y_train, X_test, y_test, target, cv=5):\n",
    "    # grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=cv)\n",
    "    # grid_search = RandomizedSearchCV(estimator=estimator, param_grid=param_grid, cv=cv)\n",
    "    # grid_search = HalvingGridSearchCV(estimator=estimator, param_distributions=param_grid, cv=cv)\n",
    "    grid_search = HalvingRandomSearchCV(estimator=estimator,param_distributions=param_grid, cv=cv)\n",
    "\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # print(grid_search.best_params_, grid_search.best_score_)\n",
    "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    y_predict = best_model.predict(X_test)\n",
    "    print(\"Test score:\", test_score)\n",
    "    print(\"Report:\")\n",
    "    report = classification_report(y_test, y_predict, target_names=target, zero_division=0)\n",
    "    # print(classification_report(y_test, y_predict, target_names=target, zero_division=0))\n",
    "    return best_model, report, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def parse_report( method, params, report, csv_dir):\n",
    "    \"\"\"\n",
    "    method: [task, classifer, hyperparameters]\n",
    "    \"\"\"\n",
    "    # Parse the classification report\n",
    "    print(report)\n",
    "    type(report)\n",
    "    lines = report.split('\\n')\n",
    "    data = lines[-3:]\n",
    "    values = [line.split() for line in data]\n",
    "\n",
    "    # Extract the desired values\n",
    "    precision = float(values[0][2])\n",
    "    recall = float(values[0][3])\n",
    "    f1_score = float(values[0][4])\n",
    "\n",
    "    # Extract the desired values\n",
    "    Wprecision = float(values[1][2])\n",
    "    Wrecall = float(values[1][3])\n",
    "    Wf1_score = float(values[1][4])\n",
    "\n",
    "    # Print the extracted values\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1_score}, WPrecision: {Wprecision}, WRecall: {Wrecall}, WF1-score: {Wf1_score}\")\n",
    "    with open(csv_dir,'a',newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(method)\n",
    "        writer.writerow(params.keys())\n",
    "        writer.writerow(params.values())\n",
    "        writer.writerow([precision,recall,f1_score,Wprecision,Wrecall,Wf1_score])\n",
    "        writer.writerow([])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 使用随机森林预测一个frame\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_predict = rfc.predict(X_test)\n",
    "\n",
    "for i in range(len(target)):\n",
    "    print(f\"----------------------Task {i}----------------------\")\n",
    "    print(classification_report(y_test[:,i], y_predict[:,i], target_names=target[i],zero_division=0))\n",
    "    num_of_cls(y_predict[:,i],target[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'class_weight': {0: 1.0466781214203895, 1: 1.7437977099236641, 2: 0.6067397078353254, 3: 1.215093085106383}}\n",
      "Best cross-validation score: 0.462454780361757\n",
      "Test score: 0.4842681258549932\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.53      0.31      0.39       183\n",
      "           中       0.25      0.01      0.02       103\n",
      "           弱       0.47      0.85      0.61       309\n",
      "    没有回应（忽视）       0.52      0.24      0.33       136\n",
      "\n",
      "    accuracy                           0.48       731\n",
      "   macro avg       0.44      0.35      0.34       731\n",
      "weighted avg       0.46      0.48      0.42       731\n",
      "\n",
      "Precision: 0.44, Recall: 0.35, F1-score: 0.34, WPrecision: 0.46, WRecall: 0.48, WF1-score: 0.42\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight':[class_weight_dict[0]] \n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "RandomForest,report,param = GridSearch(estimator=rfc, \n",
    "                            param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y1_train, \n",
    "                            X_test=X_test, y_test=y1_test,\n",
    "                            target=target[0], cv=5)\n",
    "                            \n",
    "parse_report(method=[\"task1\",\"RandomForest\"], params = param, report=report, csv_dir=\"result.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 10, 'class_weight': {0: 0.5891360412637009, 1: 1.132280049566295, 2: 2.3842139595564253}}\n",
      "Best cross-validation score: 0.6150736073989224\n",
      "Test score: 0.6196990424076607\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中性       0.62      0.88      0.73       401\n",
      "          积极       0.64      0.43      0.51       218\n",
      "          消极       0.54      0.06      0.11       112\n",
      "\n",
      "    accuracy                           0.62       731\n",
      "   macro avg       0.60      0.46      0.45       731\n",
      "weighted avg       0.61      0.62      0.57       731\n",
      "\n",
      "Precision: 0.6, Recall: 0.46, F1-score: 0.45, WPrecision: 0.61, WRecall: 0.62, WF1-score: 0.57\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight':[class_weight_dict[1]] \n",
    "}\n",
    "rfc = RandomForestClassifier()\n",
    "RandomForest,report,param = GridSearch(estimator=rfc, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y2_train, \n",
    "                            X_test=X_test, y_test=y2_test,\n",
    "                            target=target[1], cv=5)\n",
    "\n",
    "parse_report(method=[\"task2\",\"RandomForest\"], params = param, report=report, csv_dir=\"result.csv\")                            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 144 is smaller than n_iter=146. Running 144 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 10, 'class_weight': {0: 0.568252487562189, 1: 4.162870159453303}}\n",
      "Best cross-validation score: 0.8764782326185836\n",
      "Test score: 0.8768809849521204\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     专注（任务中）       0.88      1.00      0.93       638\n",
      "     走神（任务外）       0.80      0.04      0.08        93\n",
      "\n",
      "    accuracy                           0.88       731\n",
      "   macro avg       0.84      0.52      0.51       731\n",
      "weighted avg       0.87      0.88      0.83       731\n",
      "\n",
      "Precision: 0.84, Recall: 0.52, F1-score: 0.51, WPrecision: 0.87, WRecall: 0.88, WF1-score: 0.83\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight':[class_weight_dict[2]] \n",
    "}\n",
    "rfc = RandomForestClassifier()\n",
    "RandomForest,report,param = GridSearch(estimator=rfc, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y3_train, \n",
    "                            X_test=X_test, y_test=y3_test,\n",
    "                            target=target[2], cv=5)\n",
    "                            \n",
    "parse_report(method=[\"task3\",\"RandomForest\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 20, 'class_weight': {0: 35.14423076923077, 1: 11.71474358974359, 2: 1.2314690026954178, 3: 22.84375, 4: 0.44704011741682975, 5: 0.43720095693779903, 6: 0.40756021409455845, 7: 19.036458333333332}}\n",
      "Best cross-validation score: 0.44929427687548334\n",
      "Test score: 0.4377564979480164\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          玩乐       0.00      0.00      0.00         3\n",
      "          闲聊       0.00      0.00      0.00         7\n",
      "  一人独立尝试一人摸鱼       0.42      0.18      0.25        78\n",
      "        各自神游       0.00      0.00      0.00         5\n",
      "          主导       0.43      0.53      0.47       205\n",
      "          支持       0.42      0.44      0.43       207\n",
      "          旁观       0.47      0.48      0.48       219\n",
      "          冲突       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.44       731\n",
      "   macro avg       0.22      0.20      0.20       731\n",
      "weighted avg       0.42      0.44      0.42       731\n",
      "\n",
      "Precision: 0.22, Recall: 0.2, F1-score: 0.2, WPrecision: 0.42, WRecall: 0.44, WF1-score: 0.42\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight':[class_weight_dict[3]] \n",
    "}\n",
    "rfc = RandomForestClassifier()\n",
    "RandomForest,report,param = GridSearch(estimator=rfc, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y4_train, \n",
    "                            X_test=X_test, y_test=y4_test,\n",
    "                            target=target[3], cv=5)\n",
    "parse_report(method=[\"task4\",\"RandomForest\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Task 0----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.34      0.25      0.29       183\n",
      "           中       0.11      0.14      0.12       103\n",
      "           弱       0.46      0.46      0.46       309\n",
      "    没有回应（忽视）       0.28      0.33      0.30       136\n",
      "\n",
      "    accuracy                           0.34       731\n",
      "   macro avg       0.30      0.29      0.29       731\n",
      "weighted avg       0.35      0.34      0.34       731\n",
      "\n",
      "强:137, 中:128, 弱:306, 没有回应（忽视）:160, \n",
      "----------------------Task 1----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中性       0.58      0.63      0.60       401\n",
      "          积极       0.36      0.31      0.33       218\n",
      "          消极       0.18      0.16      0.17       112\n",
      "\n",
      "    accuracy                           0.47       731\n",
      "   macro avg       0.37      0.37      0.37       731\n",
      "weighted avg       0.45      0.47      0.46       731\n",
      "\n",
      "中性:439, 积极:190, 消极:102, \n",
      "----------------------Task 2----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     专注（任务中）       0.90      0.90      0.90       638\n",
      "     走神（任务外）       0.31      0.31      0.31        93\n",
      "\n",
      "    accuracy                           0.82       731\n",
      "   macro avg       0.60      0.60      0.60       731\n",
      "weighted avg       0.82      0.82      0.82       731\n",
      "\n",
      "专注（任务中）:637, 走神（任务外）:94, \n",
      "----------------------Task 3----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          玩乐       0.00      0.00      0.00         3\n",
      "          闲聊       0.00      0.00      0.00         7\n",
      "  一人独立尝试一人摸鱼       0.28      0.28      0.28        78\n",
      "        各自神游       0.17      0.20      0.18         5\n",
      "          主导       0.36      0.37      0.36       205\n",
      "          支持       0.29      0.29      0.29       207\n",
      "          旁观       0.37      0.37      0.37       219\n",
      "          冲突       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.32       731\n",
      "   macro avg       0.18      0.19      0.18       731\n",
      "weighted avg       0.32      0.32      0.32       731\n",
      "\n",
      "玩乐:3, 闲聊:9, 一人独立尝试一人摸鱼:78, 各自神游:6, 主导:207, 支持:206, 旁观:218, 冲突:4, \n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 建立决策树分类器\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "for i in range(len(target)):\n",
    "    print(f\"----------------------Task {i}----------------------\")\n",
    "    print(classification_report(y_test[:,i], y_predict[:,i], target_names=target[i],zero_division=0))\n",
    "    num_of_cls(y_predict[:,i],target[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 90, 'criterion': 'entropy', 'class_weight': {0: 1.0466781214203895, 1: 1.7437977099236641, 2: 0.6067397078353254, 3: 1.215093085106383}}\n",
      "Best cross-validation score: 0.3076916451335056\n",
      "Test score: 0.3967168262653899\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.36      0.31      0.33       183\n",
      "           中       0.19      0.21      0.20       103\n",
      "           弱       0.53      0.51      0.52       309\n",
      "    没有回应（忽视）       0.33      0.40      0.36       136\n",
      "\n",
      "    accuracy                           0.40       731\n",
      "   macro avg       0.35      0.36      0.35       731\n",
      "weighted avg       0.40      0.40      0.40       731\n",
      "\n",
      "Precision: 0.35, Recall: 0.36, F1-score: 0.35, WPrecision: 0.4, WRecall: 0.4, WF1-score: 0.4\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 120, 150],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight':[class_weight_dict[0]] \n",
    "}\n",
    "clf = DecisionTreeClassifier()\n",
    "DT,report,param = GridSearch(estimator=clf, \n",
    "                param_grid=param_grid, \n",
    "                X_train=X_train, y_train=y1_train, \n",
    "                X_test=X_test, y_test=y1_test,\n",
    "                target=target[0], cv=5)\n",
    "parse_report(method=[\"task1\",\"DT\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 150, 'criterion': 'entropy', 'class_weight': {0: 0.5891360412637009, 1: 1.132280049566295, 2: 2.3842139595564253}}\n",
      "Best cross-validation score: 0.4985609435323067\n",
      "Test score: 0.466484268125855\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中性       0.57      0.60      0.58       401\n",
      "          积极       0.36      0.33      0.34       218\n",
      "          消极       0.26      0.26      0.26       112\n",
      "\n",
      "    accuracy                           0.47       731\n",
      "   macro avg       0.40      0.40      0.40       731\n",
      "weighted avg       0.46      0.47      0.46       731\n",
      "\n",
      "Precision: 0.4, Recall: 0.4, F1-score: 0.4, WPrecision: 0.46, WRecall: 0.47, WF1-score: 0.46\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 120, 150],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight':[class_weight_dict[1]] \n",
    "}\n",
    "clf = DecisionTreeClassifier()\n",
    "DT,report,param = GridSearch(estimator=clf, \n",
    "                param_grid=param_grid, \n",
    "                X_train=X_train, y_train=y2_train, \n",
    "                X_test=X_test, y_test=y2_test,\n",
    "                target=target[1], cv=5)\n",
    "\n",
    "parse_report(method=[\"task2\",\"DT\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'gini', 'class_weight': {0: 0.568252487562189, 1: 4.162870159453303}}\n",
      "Best cross-validation score: 0.8258017046974736\n",
      "Test score: 0.841313269493844\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     专注（任务中）       0.92      0.90      0.91       638\n",
      "     走神（任务外）       0.39      0.46      0.43        93\n",
      "\n",
      "    accuracy                           0.84       731\n",
      "   macro avg       0.66      0.68      0.67       731\n",
      "weighted avg       0.85      0.84      0.85       731\n",
      "\n",
      "Precision: 0.66, Recall: 0.68, F1-score: 0.67, WPrecision: 0.85, WRecall: 0.84, WF1-score: 0.85\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 120, 150],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight':[class_weight_dict[2]] \n",
    "}\n",
    "clf = DecisionTreeClassifier()\n",
    "DT,report,param = GridSearch(estimator=clf, \n",
    "                param_grid=param_grid, \n",
    "                X_train=X_train, y_train=y3_train, \n",
    "                X_test=X_test, y_test=y3_test,\n",
    "                target=target[2], cv=5)\n",
    "\n",
    "\n",
    "parse_report(method=[\"task3\",\"DT\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20, 'criterion': 'entropy', 'class_weight': {0: 35.14423076923077, 1: 11.71474358974359, 2: 1.2314690026954178, 3: 22.84375, 4: 0.44704011741682975, 5: 0.43720095693779903, 6: 0.40756021409455845, 7: 19.036458333333332}}\n",
      "Best cross-validation score: 0.33812516112400104\n",
      "Test score: 0.31600547195622436\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          玩乐       0.00      0.00      0.00         3\n",
      "          闲聊       0.00      0.00      0.00         7\n",
      "  一人独立尝试一人摸鱼       0.14      0.13      0.14        78\n",
      "        各自神游       0.00      0.00      0.00         5\n",
      "          主导       0.32      0.32      0.32       205\n",
      "          支持       0.34      0.34      0.34       207\n",
      "          旁观       0.37      0.38      0.38       219\n",
      "          冲突       0.20      0.14      0.17         7\n",
      "\n",
      "    accuracy                           0.32       731\n",
      "   macro avg       0.17      0.16      0.17       731\n",
      "weighted avg       0.31      0.32      0.31       731\n",
      "\n",
      "Precision: 0.17, Recall: 0.16, F1-score: 0.17, WPrecision: 0.31, WRecall: 0.32, WF1-score: 0.31\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 120, 150],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight':[class_weight_dict[3]] \n",
    "}\n",
    "clf = DecisionTreeClassifier()\n",
    "DT,report,param = GridSearch(estimator=clf, \n",
    "                param_grid=param_grid, \n",
    "                X_train=X_train, y_train=y4_train, \n",
    "                X_test=X_test, y_test=y4_test,\n",
    "                target=target[3], cv=5)\n",
    "\n",
    "\n",
    "parse_report(method=[\"task4\",\"DT\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 建立KNN分类器\n",
    "clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'weights': 'uniform', 'p': 1, 'n_neighbors': 18, 'leaf_size': 19}\n",
      "Best cross-validation score: 0.3874074074074074\n",
      "Test score: 0.42818057455540354\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.37      0.25      0.30       183\n",
      "           中       0.58      0.07      0.12       103\n",
      "           弱       0.44      0.77      0.56       309\n",
      "    没有回应（忽视）       0.42      0.16      0.23       136\n",
      "\n",
      "    accuracy                           0.43       731\n",
      "   macro avg       0.45      0.31      0.30       731\n",
      "weighted avg       0.44      0.43      0.37       731\n",
      "\n",
      "Precision: 0.45, Recall: 0.31, F1-score: 0.3, WPrecision: 0.44, WRecall: 0.43, WF1-score: 0.37\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 31)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': list(range(1, 51))\n",
    "}\n",
    "clf = KNeighborsClassifier()\n",
    "KNN,report,param = GridSearch(estimator=clf, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y1_train, \n",
    "                            X_test=X_test, y_test=y1_test,\n",
    "                            target=target[0], cv=5)\n",
    "parse_report(method=[\"task1\",\"KNN\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'weights': 'uniform', 'p': 2, 'n_neighbors': 28, 'leaf_size': 34}\n",
      "Best cross-validation score: 0.5745266075544809\n",
      "Test score: 0.5649794801641587\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中性       0.57      0.93      0.70       401\n",
      "          积极       0.55      0.18      0.27       218\n",
      "          消极       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.56       731\n",
      "   macro avg       0.37      0.37      0.32       731\n",
      "weighted avg       0.47      0.56      0.47       731\n",
      "\n",
      "Precision: 0.37, Recall: 0.37, F1-score: 0.32, WPrecision: 0.47, WRecall: 0.56, WF1-score: 0.47\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 29)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': list(range(1, 51))\n",
    "}\n",
    "clf = KNeighborsClassifier()\n",
    "KNN,report,param = GridSearch(estimator=clf, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y2_train, \n",
    "                            X_test=X_test, y_test=y2_test,\n",
    "                            target=target[1], cv=6)\n",
    "parse_report(method=[\"task2\",\"KNN\"], params = param, report=report, csv_dir=\"result.csv\")                             "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'weights': 'uniform', 'p': 1, 'n_neighbors': 26, 'leaf_size': 49}\n",
      "Best cross-validation score: 0.8808324679820008\n",
      "Test score: 0.8727770177838577\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     专注（任务中）       0.87      1.00      0.93       638\n",
      "     走神（任务外）       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.87       731\n",
      "   macro avg       0.44      0.50      0.47       731\n",
      "weighted avg       0.76      0.87      0.81       731\n",
      "\n",
      "Precision: 0.44, Recall: 0.5, F1-score: 0.47, WPrecision: 0.76, WRecall: 0.87, WF1-score: 0.81\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 29)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': list(range(1, 51))\n",
    "}\n",
    "clf = KNeighborsClassifier()\n",
    "KNN,report,param = GridSearch(estimator=clf, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y3_train, \n",
    "                            X_test=X_test, y_test=y3_test,\n",
    "                            target=target[2], cv=10)\n",
    "\n",
    "parse_report(method=[\"task3\",\"KNN\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'weights': 'distance', 'p': 2, 'n_neighbors': 24, 'leaf_size': 39}\n",
      "Best cross-validation score: 0.35942360574031107\n",
      "Test score: 0.34746922024623805\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          玩乐       0.00      0.00      0.00         3\n",
      "          闲聊       0.00      0.00      0.00         7\n",
      "  一人独立尝试一人摸鱼       0.00      0.00      0.00        78\n",
      "        各自神游       0.00      0.00      0.00         5\n",
      "          主导       0.37      0.37      0.37       205\n",
      "          支持       0.35      0.18      0.24       207\n",
      "          旁观       0.34      0.64      0.44       219\n",
      "          冲突       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.35       731\n",
      "   macro avg       0.13      0.15      0.13       731\n",
      "weighted avg       0.30      0.35      0.30       731\n",
      "\n",
      "Precision: 0.13, Recall: 0.15, F1-score: 0.13, WPrecision: 0.3, WRecall: 0.35, WF1-score: 0.3\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 29)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': list(range(1, 51))\n",
    "}\n",
    "clf = KNeighborsClassifier()\n",
    "KNN,report,param = GridSearch(estimator=clf, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y4_train, \n",
    "                            X_test=X_test, y_test=y4_test,\n",
    "                            target=target[3], cv=5)\n",
    "parse_report(method=[\"task4\",\"KNN\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "结果很差 看warning原因应该是有一些结果直接没有分类  \n",
    "看看是否需要调参数或者直接去掉 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'kernel': 'rbf', 'gamma': 'scale', 'class_weight': {0: 1.0466781214203895, 1: 1.7437977099236641, 2: 0.6067397078353254, 3: 1.215093085106383}, 'C': 10}\n",
      "Best cross-validation score: 0.4086821705426356\n",
      "Test score: 0.4008207934336525\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.38      0.36      0.37       183\n",
      "           中       0.20      0.17      0.19       103\n",
      "           弱       0.48      0.51      0.50       309\n",
      "    没有回应（忽视）       0.36      0.38      0.37       136\n",
      "\n",
      "    accuracy                           0.40       731\n",
      "   macro avg       0.36      0.36      0.36       731\n",
      "weighted avg       0.40      0.40      0.40       731\n",
      "\n",
      "Precision: 0.36, Recall: 0.36, F1-score: 0.36, WPrecision: 0.4, WRecall: 0.4, WF1-score: 0.4\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7)),\n",
    "    'class_weight':[class_weight_dict[0]]\n",
    "}\n",
    "clf = SVC()\n",
    "svm,report,param = GridSearch(estimator=clf, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y1_train, \n",
    "                            X_test=X_test, y_test=y1_test,\n",
    "                            target=target[0], cv=5)\n",
    "\n",
    "parse_report(method=[\"task1\",\"SVM\"], params = param, report=report, csv_dir=\"result.csv\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'kernel': 'rbf', 'gamma': 1000.0, 'class_weight': {0: 0.5891360412637009, 1: 1.132280049566295, 2: 2.3842139595564253}, 'C': 10}\n",
      "Best cross-validation score: 0.5751304569173985\n",
      "Test score: 0.5485636114911081\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中性       0.55      1.00      0.71       401\n",
      "          积极       0.00      0.00      0.00       218\n",
      "          消极       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.55       731\n",
      "   macro avg       0.18      0.33      0.24       731\n",
      "weighted avg       0.30      0.55      0.39       731\n",
      "\n",
      "Precision: 0.18, Recall: 0.33, F1-score: 0.24, WPrecision: 0.3, WRecall: 0.55, WF1-score: 0.39\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7)),\n",
    "    'class_weight':[class_weight_dict[1]]\n",
    "}\n",
    "clf = SVC()\n",
    "svm,report,param = GridSearch(estimator=clf, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y2_train, \n",
    "                            X_test=X_test, y_test=y2_test,\n",
    "                            target=target[1], cv=5)\n",
    "\n",
    "parse_report(method=[\"task2\",\"SVM\"], params = param, report=report, csv_dir=\"result.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "146 fits failed out of a total of 730.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "146 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 201, in fit\n",
      "    y = self._validate_targets(y)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 749, in _validate_targets\n",
      "    raise ValueError(\n",
      "ValueError: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.56969697 0.8969697  0.88030303 0.88030303\n",
      " 0.56969697 0.88030303 0.8969697  0.56969697 0.56969697 0.53636364\n",
      " 0.88030303 0.88030303 0.88030303 0.8969697  0.72878788 0.8969697\n",
      " 0.88030303 0.76969697 0.60454545 0.56969697 0.61969697 0.8469697\n",
      " 0.8969697  0.56969697 0.56969697 0.8969697  0.53636364 0.56969697\n",
      " 0.56969697 0.56969697 0.56969697 0.8469697  0.56969697 0.56969697\n",
      " 0.8469697  0.8969697  0.8469697  0.8969697  0.57121212 0.8969697\n",
      " 0.56969697 0.56969697 0.56969697 0.8969697  0.56969697 0.8969697\n",
      " 0.8969697  0.88030303 0.56969697]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.64609929 1.         1.         1.\n",
      " 0.64609929 1.         1.         0.64609929 0.64609929 0.6248227\n",
      " 1.         1.         1.         0.99574468 0.94468085 1.\n",
      " 1.         0.9248227  0.51427305 0.64609929 0.71817376 1.\n",
      " 1.         0.65035461 0.65035461 1.         0.6248227  0.64609929\n",
      " 0.64609929 0.64609929 0.70930851 1.         0.64609929 0.65460993\n",
      " 1.         1.         1.         1.         0.70008865 0.99574468\n",
      " 0.64609929 0.65035461 0.64609929 1.         0.64609929 1.\n",
      " 1.         1.         0.64609929]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.56969697 0.8969697  0.88030303 0.88030303\n",
      " 0.56969697 0.88030303 0.8969697  0.56969697 0.56969697 0.53636364\n",
      " 0.88030303 0.88030303 0.88030303 0.8969697  0.72878788 0.8969697\n",
      " 0.88030303 0.76969697 0.60454545 0.56969697 0.61969697 0.8469697\n",
      " 0.8969697  0.56969697 0.56969697 0.8969697  0.53636364 0.56969697\n",
      " 0.56969697 0.56969697 0.56969697 0.8469697  0.56969697 0.56969697\n",
      " 0.8469697  0.8969697  0.8469697  0.8969697  0.57121212 0.8969697\n",
      " 0.56969697 0.56969697 0.56969697 0.8969697  0.56969697 0.8969697\n",
      " 0.8969697  0.88030303 0.56969697 0.81031746 0.81031746 0.81031746\n",
      " 0.81031746 0.81031746 0.8715873  0.88269841 0.88269841 0.82714286\n",
      " 0.87714286 0.8715873  0.88269841 0.8715873  0.8715873  0.88269841\n",
      " 0.86047619 0.86047619]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.64609929 1.         1.         1.\n",
      " 0.64609929 1.         1.         0.64609929 0.64609929 0.6248227\n",
      " 1.         1.         1.         0.99574468 0.94468085 1.\n",
      " 1.         0.9248227  0.51427305 0.64609929 0.71817376 1.\n",
      " 1.         0.65035461 0.65035461 1.         0.6248227  0.64609929\n",
      " 0.64609929 0.64609929 0.70930851 1.         0.64609929 0.65460993\n",
      " 1.         1.         1.         1.         0.70008865 0.99574468\n",
      " 0.64609929 0.65035461 0.64609929 1.         0.64609929 1.\n",
      " 1.         1.         0.64609929 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99160839\n",
      " 0.98883061 1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.56969697 0.8969697  0.88030303 0.88030303\n",
      " 0.56969697 0.88030303 0.8969697  0.56969697 0.56969697 0.53636364\n",
      " 0.88030303 0.88030303 0.88030303 0.8969697  0.72878788 0.8969697\n",
      " 0.88030303 0.76969697 0.60454545 0.56969697 0.61969697 0.8469697\n",
      " 0.8969697  0.56969697 0.56969697 0.8969697  0.53636364 0.56969697\n",
      " 0.56969697 0.56969697 0.56969697 0.8469697  0.56969697 0.56969697\n",
      " 0.8469697  0.8969697  0.8469697  0.8969697  0.57121212 0.8969697\n",
      " 0.56969697 0.56969697 0.56969697 0.8969697  0.56969697 0.8969697\n",
      " 0.8969697  0.88030303 0.56969697 0.81031746 0.81031746 0.81031746\n",
      " 0.81031746 0.81031746 0.8715873  0.88269841 0.88269841 0.82714286\n",
      " 0.87714286 0.8715873  0.88269841 0.8715873  0.8715873  0.88269841\n",
      " 0.86047619 0.86047619 0.87009346 0.87937002 0.86640706 0.87197992\n",
      " 0.86825891 0.86825891]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.64609929 1.         1.         1.\n",
      " 0.64609929 1.         1.         0.64609929 0.64609929 0.6248227\n",
      " 1.         1.         1.         0.99574468 0.94468085 1.\n",
      " 1.         0.9248227  0.51427305 0.64609929 0.71817376 1.\n",
      " 1.         0.65035461 0.65035461 1.         0.6248227  0.64609929\n",
      " 0.64609929 0.64609929 0.70930851 1.         0.64609929 0.65460993\n",
      " 1.         1.         1.         1.         0.70008865 0.99574468\n",
      " 0.64609929 0.65035461 0.64609929 1.         0.64609929 1.\n",
      " 1.         1.         0.64609929 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99160839\n",
      " 0.98883061 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.99118759 1.         1.\n",
      " 1.         1.        ]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.56969697 0.8969697  0.88030303 0.88030303\n",
      " 0.56969697 0.88030303 0.8969697  0.56969697 0.56969697 0.53636364\n",
      " 0.88030303 0.88030303 0.88030303 0.8969697  0.72878788 0.8969697\n",
      " 0.88030303 0.76969697 0.60454545 0.56969697 0.61969697 0.8469697\n",
      " 0.8969697  0.56969697 0.56969697 0.8969697  0.53636364 0.56969697\n",
      " 0.56969697 0.56969697 0.56969697 0.8469697  0.56969697 0.56969697\n",
      " 0.8469697  0.8969697  0.8469697  0.8969697  0.57121212 0.8969697\n",
      " 0.56969697 0.56969697 0.56969697 0.8969697  0.56969697 0.8969697\n",
      " 0.8969697  0.88030303 0.56969697 0.81031746 0.81031746 0.81031746\n",
      " 0.81031746 0.81031746 0.8715873  0.88269841 0.88269841 0.82714286\n",
      " 0.87714286 0.8715873  0.88269841 0.8715873  0.8715873  0.88269841\n",
      " 0.86047619 0.86047619 0.87009346 0.87937002 0.86640706 0.87197992\n",
      " 0.86825891 0.86825891 0.87523029 0.86780759]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.64609929 1.         1.         1.\n",
      " 0.64609929 1.         1.         0.64609929 0.64609929 0.6248227\n",
      " 1.         1.         1.         0.99574468 0.94468085 1.\n",
      " 1.         0.9248227  0.51427305 0.64609929 0.71817376 1.\n",
      " 1.         0.65035461 0.65035461 1.         0.6248227  0.64609929\n",
      " 0.64609929 0.64609929 0.70930851 1.         0.64609929 0.65460993\n",
      " 1.         1.         1.         1.         0.70008865 0.99574468\n",
      " 0.64609929 0.65035461 0.64609929 1.         0.64609929 1.\n",
      " 1.         1.         0.64609929 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99160839\n",
      " 0.98883061 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.99118759 1.         1.\n",
      " 1.         1.         1.         0.99289694]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'kernel': 'rbf', 'gamma': 100.0, 'class_weight': {0: 0.568252487562189, 1: 4.162870159453303}, 'C': 100}\n",
      "Best cross-validation score: 0.8752302870465926\n",
      "Test score: 0.8727770177838577\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     专注（任务中）       0.87      1.00      0.93       638\n",
      "     走神（任务外）       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.87       731\n",
      "   macro avg       0.44      0.50      0.47       731\n",
      "weighted avg       0.76      0.87      0.81       731\n",
      "\n",
      "Precision: 0.44, Recall: 0.5, F1-score: 0.47, WPrecision: 0.76, WRecall: 0.87, WF1-score: 0.81\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7)),\n",
    "    'class_weight':[class_weight_dict[2]]\n",
    "}\n",
    "clf = SVC()\n",
    "svm,report,param = GridSearch(estimator=clf, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y3_train, \n",
    "                            X_test=X_test, y_test=y3_test,\n",
    "                            target=target[2], cv=5)\n",
    "parse_report(method=[\"task3\",\"SVM\"], params = param, report=report, csv_dir=\"result.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'kernel': 'rbf', 'gamma': 10.0, 'class_weight': {0: 35.14423076923077, 1: 11.71474358974359, 2: 1.2314690026954178, 3: 22.84375, 4: 0.44704011741682975, 5: 0.43720095693779903, 6: 0.40756021409455845, 7: 19.036458333333332}, 'C': 10}\n",
      "Best cross-validation score: 0.3765586061699751\n",
      "Test score: 0.3844049247606019\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          玩乐       0.00      0.00      0.00         3\n",
      "          闲聊       0.00      0.00      0.00         7\n",
      "  一人独立尝试一人摸鱼       0.55      0.08      0.13        78\n",
      "        各自神游       0.00      0.00      0.00         5\n",
      "          主导       0.41      0.38      0.40       205\n",
      "          支持       0.35      0.53      0.42       207\n",
      "          旁观       0.40      0.40      0.40       219\n",
      "          冲突       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.38       731\n",
      "   macro avg       0.21      0.17      0.17       731\n",
      "weighted avg       0.39      0.38      0.36       731\n",
      "\n",
      "Precision: 0.21, Recall: 0.17, F1-score: 0.17, WPrecision: 0.39, WRecall: 0.38, WF1-score: 0.36\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7)),\n",
    "    'class_weight':[class_weight_dict[3]]\n",
    "}\n",
    "clf = SVC()\n",
    "svm,report,param = GridSearch(estimator=clf, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y4_train, \n",
    "                            X_test=X_test, y_test=y4_test,\n",
    "                            target=target[3], cv=5)\n",
    "parse_report(method=[\"task4\",\"SVM\"], params = param, report=report, csv_dir=\"result.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# 定义模型参数\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 4,\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "# 将数据转换为DMatrix格式\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# 训练模型\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# 在测试集上预测\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          玩乐       0.00      0.00      0.00         3\n",
      "          闲聊       1.00      0.14      0.25         7\n",
      "  一人独立尝试一人摸鱼       0.40      0.32      0.35        78\n",
      "        各自神游       0.00      0.00      0.00         5\n",
      "          主导       0.44      0.47      0.46       205\n",
      "          支持       0.44      0.47      0.46       207\n",
      "          旁观       0.47      0.49      0.48       219\n",
      "          冲突       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.45       731\n",
      "   macro avg       0.34      0.24      0.25       731\n",
      "weighted avg       0.44      0.45      0.44       731\n",
      "\n",
      "玩乐:0, 闲聊:1, 一人独立尝试一人摸鱼:63, 各自神游:0, 主导:218, 支持:218, 旁观:231, 冲突:0, \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 63, 0, 218, 218, 231, 0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用随机森林预测一个frame\n",
    "xgb = XGBClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y4_train)\n",
    "\n",
    "# 在测试集上预测\n",
    "y_predict = xgb.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y4_test, y_predict, target_names=target[3],zero_division=0))\n",
    "num_of_cls(y_predict,target[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# 定义xgboost分类器模型\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xbgs,report,param = GridSearch(estimator=xgb, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y1_train, \n",
    "                            X_test=X_test, y_test=y1_test,\n",
    "                            target=target[0], cv=5)\n",
    "parse_report(method=[\"task1\",\"XGBoost\"], params = param, report=report, csv_dir=\"result.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'subsample': 0.9, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 15, 'learning_rate': 0.05, 'gamma': 0.3, 'colsample_bytree': 0.6}\n",
      "Best cross-validation score: 0.6422459802299436\n",
      "Test score: 0.6292749658002736\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          中性       0.61      0.93      0.74       401\n",
      "          积极       0.71      0.38      0.49       218\n",
      "          消极       0.83      0.04      0.08       112\n",
      "\n",
      "    accuracy                           0.63       731\n",
      "   macro avg       0.72      0.45      0.44       731\n",
      "weighted avg       0.68      0.63      0.56       731\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.3, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.3, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.3, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xbgs,report,param = GridSearch(estimator=xgb, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y2_train, \n",
    "                            X_test=X_test, y_test=y2_test,\n",
    "                            target=target[1], cv=5)\n",
    "parse_report(method=[\"task2\",\"XGBoost\"], params = param, report=report, csv_dir=\"result.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
      "Best cross-validation score: 0.8857374918778428\n",
      "Test score: 0.8919288645690835\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     专注（任务中）       0.90      0.99      0.94       638\n",
      "     走神（任务外）       0.79      0.20      0.32        93\n",
      "\n",
      "    accuracy                           0.89       731\n",
      "   macro avg       0.84      0.60      0.63       731\n",
      "weighted avg       0.88      0.89      0.86       731\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xbgs,report,param = GridSearch(estimator=xgb, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y3_train, \n",
    "                            X_test=X_test, y_test=y3_test,\n",
    "                            target=target[2], cv=5)\n",
    "parse_report(method=[\"task3\",\"XGBoost\"], params = param, report=report, csv_dir=\"result.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "154 fits failed out of a total of 176.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [0 1 2 4 5 6 7]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [2 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [0 1 2 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [1 2 3 4 5 6 7]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got [1 2 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 4 5 6 7]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "24 fits failed out of a total of 64.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [1 2 3 4 5 6 7]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [0 1 2 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.43385174 0.42772679 0.41907051]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 1.         1.         0.99987599]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'subsample': 0.6, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 15, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Best cross-validation score: 0.43385173853923853\n",
      "Test score: 0.46785225718194257\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          玩乐       0.00      0.00      0.00         3\n",
      "          闲聊       0.00      0.00      0.00         7\n",
      "  一人独立尝试一人摸鱼       0.45      0.35      0.39        78\n",
      "        各自神游       0.00      0.00      0.00         5\n",
      "          主导       0.46      0.49      0.48       205\n",
      "          支持       0.46      0.48      0.47       207\n",
      "          旁观       0.49      0.53      0.51       219\n",
      "          冲突       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.47       731\n",
      "   macro avg       0.23      0.23      0.23       731\n",
      "weighted avg       0.45      0.47      0.46       731\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb = XGBClassifier()\n",
    "xbgs,report,param = GridSearch(estimator=xgb, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y4_train, \n",
    "                            X_test=X_test, y_test=y4_test,\n",
    "                            target=target[3], cv=8)\n",
    "parse_report(method=[\"task4\",\"XGBoost\"], params = param, report=report, csv_dir=\"result.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM  \n",
    "not working so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "154 fits failed out of a total of 176.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [0 1 2 4 5 6 7]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [2 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [0 1 2 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [1 2 3 4 5 6 7]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got [1 2 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 4 5 6 7]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "24 fits failed out of a total of 64.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [1 2 3 4 5 6 7]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [0 1 2 4 5 6]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1440, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.43385174 0.42772679 0.41907051]\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 1.         1.         0.99987599]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb = XGBClassifier()\n",
    "GridSearch(estimator=xgb, param_grid=param_grid, \n",
    "                            X_train=X_train, y_train=y4_train, \n",
    "                            X_test=X_test, y_test=y4_test,\n",
    "                            target=target[3], cv=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 4) # 4 classes\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out, _ = self.lstm(x) # 1 * 100\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "        \n",
    "class mil_regression(nn.Module):\n",
    "    def __init__(self, input_size=786, hidden_size=100, num_layers=1, output_size=1):\n",
    "        ''' use LSTM for MIL '''\n",
    "        super(mil_regression, self).__init__()\n",
    "        self.net = LSTM(input_size, hidden_size, num_layers)\n",
    "        self.class_num = output_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input shape: (frame_num, feature_size)\n",
    "        \n",
    "\n",
    "        self.seg_num, self.feature_num = inputs.shape #\n",
    "\n",
    "        # outputs = torch.zeros((self.seg_num, self.class_num)).double.cuda() #  frame * 4（bool）\n",
    "\n",
    "        outputs = self.net(inputs)\n",
    "        # for i in range(self.seg_num):\n",
    "        #     outputs[i,:] = self.net(inputs[i]) # 786\n",
    "\n",
    "        # for idx, seg in enumerate(inputs):\n",
    "        #     seg = Variable(seg).cuda()\n",
    "        #     outputs[idx] = self.net(seg)\n",
    "\n",
    "        # 视频特征 = frame取平均\n",
    "        output = torch.mean(outputs, 1).cuda()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "model = mil_regression().cuda()\n",
    "\n",
    "epochs = 150\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X_train)): # 每次处理一个视频(对batch)\n",
    "\n",
    "        x = torch.tensor(X_train[i]).float().cuda()\n",
    "        y = torch.tensor(y_train[i]).float().cuda()\n",
    "        \n",
    "\n",
    "        if len(x.shape) ==1:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x)\n",
    "\n",
    "        single_loss = loss_function(y_pred, y)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if (i+1) % 10 == 0:\n",
    "        #     print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, len(X_train), single_loss.item()))\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(X_test)): # 每次处理一个视频(对batch)\n",
    "        x = torch.tensor(X_test[i]).float().cuda()\n",
    "        y = torch.tensor(y_test[i]).float().cuda()\n",
    "        print(y)\n",
    "\n",
    "        if len(x.shape) ==1:\n",
    "            continue\n",
    "\n",
    "        outputs = model(x)\n",
    "        print(outputs)\n",
    "        correct += (outputs == y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3. ,  3. ,  3. ],\n",
      "       [ 2. ,  3. , 48.5],\n",
      "       [ 0.5,  1.5, 47. ],\n",
      "       [ 0. ,  0. ,  0. ]]), array([[ 1. ,  1. ,  1. ],\n",
      "       [ 1. ,  1. ,  1. ],\n",
      "       [ 3. , 47.5, 92. ],\n",
      "       [ 3. , 47.5, 92. ]])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维矩阵\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [5, 8, 100],[5, 8, 100]])\n",
    "\n",
    "# 计算梯度\n",
    "dy = np.gradient(x)\n",
    "\n",
    "# 输出结果\n",
    "print(dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([nan, nan])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162420/1742590338.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  d2x.append(np.diff(dx2-dx1) / np.diff(dx3-dx2))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维数组\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算每一行相邻行之间的二阶导数\n",
    "d2x = []\n",
    "for i in range(1, x.shape[0]-1):\n",
    "    dx1 = np.gradient(x[i-1, :])\n",
    "    dx2 = np.gradient(x[i, :])\n",
    "    dx3 = np.gradient(x[i+1, :])\n",
    "    d2x.append(np.diff(dx2-dx1) / np.diff(dx3-dx2))\n",
    "\n",
    "# 输出结果\n",
    "print(d2x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 1.]), array([1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维数组\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算每一行数据对上一行数据的导数\n",
    "dx = []\n",
    "for i in range(1, x.shape[0]):\n",
    "    diff = np.diff(x[i, :]) / np.diff(x[i-1, :])\n",
    "    dx.append(diff)\n",
    "\n",
    "# 输出结果\n",
    "print(dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame  feature\n",
      "0      1      1.0\n",
      "1      2      3.0\n",
      "2      3      5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设df是一个DataFrame对象，其中包含frame和feature两列\n",
    "df = pd.DataFrame({'frame': [1, 3], 'feature': [1, 5]})\n",
    "\n",
    "# 将df的索引设置为frame列，并增加需要插值的索引值\n",
    "df = df.set_index('frame').reindex(range(df['frame'].min(), df['frame'].max()+1))\n",
    "\n",
    "# 对df进行插值\n",
    "df_interpolated = df.interpolate().reset_index()\n",
    "\n",
    "# 输出插值结果\n",
    "print(df_interpolated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1de83ba939c2ac04c4cd5f42769ee29bf75010bc15e3148e0552f0994dd76a71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

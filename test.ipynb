{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch \n",
    "# !pip install scikit-learn\n",
    "# !pip install sklearn_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ln -s ~/Downloads/siblings_pose siblings_pose\n",
    "# !ln -s ~/Downloads/siblings_face siblings_face"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[example](https://zhuanlan.zhihu.com/p/82810188)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 视频的label是对视频整体的，但Feature却是逐帧的。\n",
    "\n",
    "为了聚合帧级预测得到视频级预测结果，提出四种方式：\n",
    "\n",
    "1）使用最后一个时间帧的预测结果为最终视频预测结果；√  \n",
    "\n",
    "2）对所有时序帧的预测结果进行最大池化得到最终结果；\n",
    "\n",
    "3）加和所有帧预测结果，并取最大值；\n",
    "\n",
    "4）结合g对每帧预测结果进行线性加权，求和并返回最大值\n",
    "\n",
    "对于简单分类器\n",
    "- 实际处理中将视频的label复制到每个frame中    \n",
    "- 如此问题转变为简单的分类问题\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Face Feature**  \n",
    "frame, face_id, timestamp, confidence, success，[709*features]\n",
    "\n",
    "- 分别放入 每次放入一个person  \n",
    "person * frame  * feature  \n",
    "2      * frame  * 709  \n",
    "\n",
    "- 共同放入  \n",
    "frame * 1418  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要分别读入face和pose的数据并对应起来\n",
    "- 对于siblings_face 需要读入json  \n",
    "- 对于siblings_pose 需要读入csv    \n",
    "- 对于Label 需要读入csv\n",
    "\n",
    "\n",
    "*特别注意对于face，需要去除置信度小于阈值的数据  \n",
    "*要将video的label扩展到每个frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "face_feature_file = \"face.csv\" # note that this is only single video feat\n",
    "\n",
    "with open(\"face.csv\", newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    # for row in spamreader:\n",
    "        # print(', '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>face_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>confidence</th>\n",
       "      <th>success</th>\n",
       "      <th>gaze_0_x</th>\n",
       "      <th>gaze_0_y</th>\n",
       "      <th>gaze_0_z</th>\n",
       "      <th>gaze_1_x</th>\n",
       "      <th>gaze_1_y</th>\n",
       "      <th>...</th>\n",
       "      <th>AU12_c</th>\n",
       "      <th>AU14_c</th>\n",
       "      <th>AU15_c</th>\n",
       "      <th>AU17_c</th>\n",
       "      <th>AU20_c</th>\n",
       "      <th>AU23_c</th>\n",
       "      <th>AU25_c</th>\n",
       "      <th>AU26_c</th>\n",
       "      <th>AU28_c</th>\n",
       "      <th>AU45_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037185</td>\n",
       "      <td>0.380190</td>\n",
       "      <td>-0.924161</td>\n",
       "      <td>-0.258944</td>\n",
       "      <td>0.495936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.401678</td>\n",
       "      <td>-0.914732</td>\n",
       "      <td>-0.255940</td>\n",
       "      <td>0.517694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame  face_id  timestamp  confidence  success  gaze_0_x  gaze_0_y   \n",
       "0      1        0      0.000        0.98        1  0.037185  0.380190  \\\n",
       "1      1        1      0.000        0.73        0  0.000000  0.000000   \n",
       "2      1        2      0.000        0.03        0  0.000000  0.000000   \n",
       "3      2        0      0.033        0.98        1  0.043811  0.401678   \n",
       "4      2        1      0.033        0.73        0  0.000000  0.000000   \n",
       "\n",
       "   gaze_0_z  gaze_1_x  gaze_1_y  ...  AU12_c  AU14_c  AU15_c  AU17_c  AU20_c   \n",
       "0 -0.924161 -0.258944  0.495936  ...     0.0     0.0     0.0     1.0     1.0  \\\n",
       "1  0.000000  0.000000  0.000000  ...     1.0     0.0     1.0     0.0     0.0   \n",
       "2  0.000000  0.000000  0.000000  ...     1.0     1.0     1.0     0.0     1.0   \n",
       "3 -0.914732 -0.255940  0.517694  ...     0.0     0.0     1.0     0.0     0.0   \n",
       "4  0.000000  0.000000  0.000000  ...     1.0     0.0     1.0     0.0     0.0   \n",
       "\n",
       "   AU23_c  AU25_c  AU26_c  AU28_c  AU45_c  \n",
       "0     0.0     0.0     1.0     0.0     1.0  \n",
       "1     1.0     1.0     1.0     0.0     0.0  \n",
       "2     1.0     0.0     0.0     1.0     0.0  \n",
       "3     0.0     0.0     1.0     0.0     1.0  \n",
       "4     1.0     1.0     1.0     1.0     0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x_train = pd.read_csv(\"face.csv\")\n",
    "x_train.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "# print(x_train.shape) # 204 * 714\n",
    "x = x_train[:,5:714] # x * 709\n",
    "y = x_train[:,4] # x * 1\n",
    "# batch unsqueeze\n",
    "x = np.expand_dims(x, axis=0)\n",
    "y = np.expand_dims(y, axis=0)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "> 25 hidden units LSTM layer followed by 100 units dense layer with the rectified linear unit and 2 units dense layer with softmax for LSTM.  \n",
    ">100 LSTM units for the first layer for LSTM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[torch](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)   \n",
    "[mil](https://github.com/Marsrocky/Emotiw-Engagement-Prediction/blob/master/mil_lstm.py)  \n",
    "[Engagement_Detection_OpenFace_Bi-LSTM](https://github.com/CopurOnur/Engagement_Detection_OpenFace_Bi-LSTM/blob/main/Engagement_Detection_OpenFace_Bi_LSTM_test.ipynb)  \n",
    "[action unit](https://github.com/MRzzm/action-recognition-models-pytorch/tree/master/CNN%2BLSTM/ALSTM)  \n",
    "为了聚合帧级预测得到视频级预测结果，提出四种方式：\n",
    "\n",
    "1）使用最后一个时间帧的预测结果为最终视频预测结果；\n",
    "\n",
    "2）对所有时序帧的预测结果进行最大池化得到最终结果；\n",
    "\n",
    "3）加和所有帧预测结果，并取最大值；\n",
    "\n",
    "4）结合g对每帧预测结果进行线性加权，求和并返回最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 2) # 2 classes\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out, _ = self.lstm(x) # 1 * 100\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mil_regression(nn.Module):\n",
    "    def __init__(self, input_size=709, hidden_size=100, num_layers=1, output_size=2):\n",
    "        ''' use LSTM for MIL '''\n",
    "        super(mil_regression, self).__init__()\n",
    "        self.net = LSTM(input_size, hidden_size, num_layers)\n",
    "        self.class_num = output_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input shape: (batch_num, frame_num, feature_size)\n",
    "\n",
    "        self.b, self.seg_num, self.feature_num = inputs.shape #\n",
    "        outputs = torch.zeros((self.b, self.seg_num, self.class_num)).cuda() # batch * frame * 2（bool）\n",
    "\n",
    "        for i in range(self.seg_num):\n",
    "            outputs[:,i,:] = self.net(inputs[:,i,:]).squeeze()\n",
    "\n",
    "        # for idx, seg in enumerate(inputs):\n",
    "        #     seg = Variable(seg).cuda()\n",
    "        #     outputs[idx] = self.net(seg)\n",
    "\n",
    "        # 视频特征 = frame取平均\n",
    "        output = torch.mean(outputs, 1).cuda()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m y \u001b[39m=\u001b[39m y_train[i:i\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m]\n\u001b[1;32m     24\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     28\u001b[0m single_loss \u001b[39m=\u001b[39m loss_function(y_pred, y)\n\u001b[1;32m     29\u001b[0m single_loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mmil_regression.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseg_num, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_num))\u001b[39m.\u001b[39mcuda() \u001b[39m# batch * frame * 2（bool）\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseg_num):\n\u001b[0;32m---> 15\u001b[0m     outputs[:,i,:] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(inputs[:,i,:])\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     17\u001b[0m \u001b[39m# for idx, seg in enumerate(inputs):\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m#     seg = Variable(seg).cuda()\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m#     outputs[idx] = self.net(seg)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[39m# 视频特征 = frame取平均\u001b[39;00m\n\u001b[1;32m     22\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(outputs, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     14\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x) \u001b[39m# 1 * 100\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n\u001b[1;32m     17\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    775\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    776\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    778\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at cuda:0"
     ]
    }
   ],
   "source": [
    "# dataset = OpenfaceDataset()\n",
    "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=1, num_workers=1, shuffle=True)\n",
    "# for idx, (data, target) in enumerate(train_loader):\n",
    "#     output = net(data)\n",
    "#     print (output)\n",
    "#     break\n",
    "# \n",
    "import torch \n",
    "\n",
    "model = mil_regression().cuda()\n",
    "\n",
    "x_train = torch.from_numpy(x,device=\"cuda\") \n",
    "y_train = torch.from_numpy(y,device=\"cuda\")\n",
    "\n",
    "epochs = 150\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for i in range(len(x_train)): # 每次处理一个视频(对batch)\n",
    "        x = x_train[i:i+10]\n",
    "        y = y_train[i:i+10]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        single_loss = loss_function(y_pred, y)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 153, 709])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(x_train)\n",
    "x = x.unsqueeze(0).to(torch.float)\n",
    "print(x.shape) # [1, 153, 709]\n",
    "y_pred = model(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 50 trees and maximum depth of 50 for RF  \n",
    "> 25 trees with maximum depths of 10 for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       1.00      1.00      1.00        14\n",
      "    survived       1.00      1.00      1.00        37\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dt = DictVectorizer(sparse=False)\n",
    "\n",
    "# print(x_train.to_dict(orient=\"record\"))\n",
    "# # 按行，样本名字为键，列名也为键，[{\"1\":1,\"2\":2,\"3\":3}]\n",
    "# x_train = dt.fit_transform(x_train.to_dict(orient=\"record\"))\n",
    "# x_test = dt.fit_transform(x_test.to_dict(orient=\"record\"))\n",
    "\n",
    "\n",
    "# 使用随机森林预测一个frame\n",
    "rfc = RandomForestClassifier(n_estimators=25, max_depth=10)\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc_y_predict = rfc.predict(x_test)\n",
    "print(rfc.score(x_test, y_test))\n",
    "print(classification_report(y_test, rfc_y_predict, target_names=[\"died\", \"survived\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    " # 建立随机森林分类器\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 建立决策树分类器\n",
    "clf = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 建立KNN分类器\n",
    "clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 读取特征数据\n",
    "data = pd.read_csv('feature.csv')\n",
    "\n",
    "# 将one-hot标签合并为单个列\n",
    "y = data.iloc[:, -4:].idxmax(axis=1)\n",
    "\n",
    "# 分离特征和标签\n",
    "X = data.iloc[:, :-4]\n",
    "\n",
    "# 划分训练和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# 建立SVM分类器\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "# 训练分类器\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 评估分类器性能\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELM\n",
    "[ELM sklearn](http://wdm0006.github.io/sklearn-extensions/extreme_learning_machines.html#usage)  \n",
    "[ELM](https://github.com/5663015/elm)  \n",
    "[ELM-pytorch](https://github.com/naderAsadi/ELM-Pytorch/blob/master/models.py)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 hidden units with radial basis function with 0.01 width as the activation function for ELM  \n",
    "500 hidden units for ELM;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn_extensions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextreme_learning_machines\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39melm\u001b[39;00m \u001b[39mimport\u001b[39;00m GenELMClassifier\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn_extensions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextreme_learning_machines\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrandom_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m RBFRandomLayer, MLPRandomLayer\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_classifiers\u001b[39m():\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn_extensions/extreme_learning_machines/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn_extensions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextreme_learning_machines\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39melm\u001b[39;00m \u001b[39mimport\u001b[39;00m ELMClassifier, ELMRegressor, GenELMClassifier, GenELMRegressor\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn_extensions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextreme_learning_machines\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrandom_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m RBFRandomLayer, MLPRandomLayer, GRBFRandomLayer, RandomLayer\n\u001b[1;32m      4\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mELMRegressor\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mELMClassifier\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMLPRandomLayer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     13\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn_extensions/extreme_learning_machines/elm.py:226\u001b[0m\n\u001b[1;32m    221\u001b[0m         predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_predictions()\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m predictions\n\u001b[0;32m--> 226\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGenELMClassifier\u001b[39;00m(BaseELM, ClassifierMixin):\n\u001b[1;32m    227\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m    GenELMClassifier is a classifier based on the Extreme Learning Machine.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m              2006.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hidden_layer\u001b[39m=\u001b[39mMLPRandomLayer(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), binarizer\u001b[39m=\u001b[39mLabelBinarizer(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), regressor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn_extensions/extreme_learning_machines/elm.py:267\u001b[0m, in \u001b[0;36mGenELMClassifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGenELMClassifier\u001b[39;00m(BaseELM, ClassifierMixin):\n\u001b[1;32m    227\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m    GenELMClassifier is a classifier based on the Extreme Learning Machine.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m              2006.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hidden_layer\u001b[39m=\u001b[39mMLPRandomLayer(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), binarizer\u001b[39m=\u001b[39mLabelBinarizer(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m), regressor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    268\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39m        :param hidden_layer:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39m        :return:\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[39msuper\u001b[39m(GenELMClassifier, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(hidden_layer, regressor)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn_extensions.extreme_learning_machines.elm import GenELMClassifier\n",
    "\n",
    "from sklearn_extensions.extreme_learning_machines.random_layer import RBFRandomLayer, MLPRandomLayer\n",
    "\n",
    "\n",
    "def make_classifiers():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    names = [\"ELM(10,tanh)\", \"ELM(10,tanh,LR)\", \"ELM(10,sinsq)\", \"ELM(10,tribas)\", \"ELM(hardlim)\", \"ELM(20,rbf(0.1))\"]\n",
    "\n",
    "    nh = 10\n",
    "\n",
    "    # pass user defined transfer func\n",
    "    sinsq = (lambda x: np.power(np.sin(x), 2.0))\n",
    "    srhl_sinsq = MLPRandomLayer(n_hidden=nh, activation_func=sinsq)\n",
    "\n",
    "    # use internal transfer funcs\n",
    "    srhl_tanh = MLPRandomLayer(n_hidden=nh, activation_func='tanh')\n",
    "    srhl_tribas = MLPRandomLayer(n_hidden=nh, activation_func='tribas')\n",
    "    srhl_hardlim = MLPRandomLayer(n_hidden=nh, activation_func='hardlim')\n",
    "\n",
    "    # use gaussian RBF\n",
    "    srhl_rbf = RBFRandomLayer(n_hidden=nh*2, rbf_width=0.1, random_state=0)\n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    classifiers = [GenELMClassifier(hidden_layer=srhl_tanh),\n",
    "                   GenELMClassifier(hidden_layer=srhl_tanh, regressor=log_reg),\n",
    "                   GenELMClassifier(hidden_layer=srhl_sinsq),\n",
    "                   GenELMClassifier(hidden_layer=srhl_tribas),\n",
    "                   GenELMClassifier(hidden_layer=srhl_hardlim),\n",
    "                   GenELMClassifier(hidden_layer=srhl_rbf)]\n",
    "\n",
    "    return names, classifiers\n",
    "\n",
    "# generate some datasets\n",
    "names, classifiers = make_classifiers()\n",
    "\n",
    "# iterate over datasets\n",
    "for idx, ds in enumerate(datasets):\n",
    "    # pre-process dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "    y_test = y_test.reshape(-1, )\n",
    "    y_train = y_train.reshape(-1, )\n",
    "\n",
    "    # iterate over classifiers\n",
    "    print('Dataset: %s' % (idx, ))\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print('Model %s score: %s' % (name, score))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "###############\n",
    "# ELM\n",
    "###############\n",
    "class ELM():\n",
    "    def __init__(self, input_size, h_size, num_classes, device=None):\n",
    "        self._input_size = input_size\n",
    "        self._h_size = h_size\n",
    "        self._output_size = num_classes\n",
    "        self._device = device\n",
    "\n",
    "        self._alpha = nn.init.uniform_(torch.empty(self._input_size, self._h_size, device=self._device), a=-1., b=1.)\n",
    "        self._beta = nn.init.uniform_(torch.empty(self._h_size, self._output_size, device=self._device), a=-1., b=1.)\n",
    "\n",
    "        self._bias = torch.zeros(self._h_size, device=self._device)\n",
    "\n",
    "        self._activation = torch.sigmoid\n",
    "\n",
    "    def predict(self, x):\n",
    "        h = self._activation(torch.add(x.mm(self._alpha), self._bias))\n",
    "        out = h.mm(self._beta)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def fit(self, x, t):\n",
    "        temp = x.mm(self._alpha)\n",
    "        H = self._activation(torch.add(temp, self._bias))\n",
    "\n",
    "        H_pinv = torch.pinverse(H)\n",
    "        self._beta = H_pinv.mm(t)\n",
    "\n",
    "\n",
    "    def evaluate(self, x, t):\n",
    "        y_pred = self.predict(x)\n",
    "        acc = torch.sum(torch.argmax(y_pred, dim=1) == torch.argmax(t, dim=1)).item() / len(t)\n",
    "        return acc\n",
    "\n",
    "#####################\n",
    "# Helper Functions\n",
    "#####################\n",
    "def to_onehot(batch_size, num_classes, y, device):\n",
    "    # One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "    y_onehot = torch.FloatTensor(batch_size, num_classes).to(device)\n",
    "    #y = y.type(dtype=torch.long)\n",
    "    y = torch.unsqueeze(y, dim=1)\n",
    "    # In your for loop\n",
    "    y_onehot.zero_()\n",
    "    y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "    return y_onehot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果测量\n",
    "- F1 Score  \n",
    "- Precision  \n",
    "- Recall  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 计算分类器性能指标\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

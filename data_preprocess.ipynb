{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要分别读入face和pose的数据并对应起来\n",
    "- 对于siblings_face 需要读入json  \n",
    "- 对于siblings_pose 需要读入csv    \n",
    "- 对于Label 需要读入csv\n",
    "\n",
    "\n",
    "*特别注意对于face，需要去除置信度小于阈值的数据  \n",
    "*要将video的label扩展到每个frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 读取标签文件\n",
    "label = pd.read_csv('labelA/回应情况-表格 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>切片ID</th>\n",
       "      <th>回应情况</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>强</td>\n",
       "      <td>中</td>\n",
       "      <td>弱</td>\n",
       "      <td>没有回应（忽视）</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15YS_20230317_01/VCAM_0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15YS_20230317_01/VCAM_0000_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15YS_20230317_01/VCAM_0000_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15YS_20230317_01/VCAM_0000_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           切片ID 回应情况 Unnamed: 2 Unnamed: 3 Unnamed: 4   \n",
       "0                           NaN    强          中          弱   没有回应（忽视）  \\\n",
       "1    15YS_20230317_01/VCAM_0000    0          0          1          0   \n",
       "2  15YS_20230317_01/VCAM_0000_1    0          0          1          0   \n",
       "3  15YS_20230317_01/VCAM_0000_2    1          0          0          0   \n",
       "4  15YS_20230317_01/VCAM_0000_3    0          0          1          0   \n",
       "\n",
       "   Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10   \n",
       "0         NaN         NaN         NaN         NaN         NaN          NaN  \\\n",
       "1         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "\n",
       "   Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15   \n",
       "0          NaN          NaN          NaN          NaN          NaN  \\\n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 16  Unnamed: 17  \n",
       "0          NaN          NaN  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.iloc[1,0][-4:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并读取face和pose特征  \n",
    "按照视频读取frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vel_and_acc(features):\n",
    "    \"\"\"\n",
    "    cal the mean and var of velocity and acceleration respectively of input features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_order_derivatives = np.gradient(features, axis=0)\n",
    "        second_order_derivatives = np.gradient(first_order_derivatives, axis=0)\n",
    "    except:\n",
    "        print(\"Error in get_vel_and_acc\")\n",
    "        print(features.shape)\n",
    "        print(print(f\"len:{len(face_df0)} and {len(face_df1)}\"))\n",
    "        print(max_fm)\n",
    "        print(\"------------------\")\n",
    "\n",
    "    # velecity\n",
    "    vel_means = np.mean(first_order_derivatives, axis=0)\n",
    "    vel_var = np.var(first_order_derivatives, axis=0)\n",
    "\n",
    "    # acceleration\n",
    "    acc_means = np.mean(second_order_derivatives, axis=0)\n",
    "    acc_var = np.var(second_order_derivatives, axis=0)\n",
    "    \n",
    "    return vel_means, vel_var, acc_means, acc_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[face error] in siblings_face_1024/VCAM_0000_39.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0000_53.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0000_59.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0000_69.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0000_94.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0000_95.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0000_97.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_2.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_3.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_5.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_6.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_7.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_15.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_17.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_24.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_26.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_27.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_28.csv: not enough frames\n",
      "[face error]: siblings_face_1024/VCAM_0001_29.csv not exist\n",
      "[face error] in siblings_face_1024/VCAM_0001_30.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_31.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_33.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_34.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_35.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_36.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_44.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_45.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_46.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_47.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_52.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_53.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_54.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_56.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_60.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_74.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0001_93.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_1.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_7.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_9.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_10.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_11.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_12.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_13.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_14.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_15.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_17.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_18.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_19.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_20.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_22.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_23.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_24.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_25.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_26.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_27.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_28.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_29.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_33.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_36.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_37.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_38.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_41.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_44.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_46.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_50.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_51.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_52.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_53.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_55.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_58.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_59.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_65.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_68.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_69.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_71.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_74.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_76.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_77.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_78.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_84.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_85.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_89.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0002_98.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0003_50.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0003_55.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0003_56.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0003_69.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0003_70.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0003_71.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0003_72.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_11.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_14.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_15.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_23.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_53.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_68.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_74.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_75.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_79.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_80.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_102.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_103.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_104.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_109.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_110.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_114.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_115.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_116.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_117.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_119.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_120.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_125.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_135.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_136.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_137.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_150.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_153.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_154.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_159.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_160.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_164.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_170.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_171.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0004_174.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_3.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_10.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_14.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_15.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_16.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_25.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_32.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_33.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_37.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_45.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_46.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_48.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_52.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_53.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_54.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_57.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_61.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_62.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_63.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_66.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_69.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_76.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_84.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_86.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_87.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_88.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_89.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_90.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_91.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_92.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_97.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_100.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_101.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_102.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_103.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_104.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_108.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_115.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_123.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_124.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_125.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_127.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_128.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_131.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_138.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_140.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_148.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_151.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_153.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_154.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_158.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0005_162.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_8.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_13.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_16.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_17.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_18.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_19.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_20.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_22.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_29.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_35.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_37.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_51.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_72.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_73.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_74.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_75.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_77.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_78.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_81.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_86.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_88.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_89.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_90.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_92.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_96.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_97.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_98.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_99.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_100.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_101.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_102.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_103.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_107.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_108.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_111.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_113.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_114.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_115.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_116.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_120.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_121.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_122.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_130.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_131.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_134.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_135.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_136.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_137.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_138.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_141.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0006_142.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_1.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_2.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_3.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_4.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_5.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_6.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_7.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_8.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_9.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_10.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_12.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_20.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_22.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_23.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_28.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_29.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_32.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0007_33.csv: not enough frames\n",
      "Total face feat:211411, pose feat:38514\n",
      "Read in videos X:0, face_feat:90352,pose_feat:38226\n",
      "Drop 121059 face features, 288 pose features\n"
     ]
    }
   ],
   "source": [
    "# set openface confidence threshold\n",
    "confidence_threshold = 0.1\n",
    "\n",
    "# 导入特征并对齐标签\n",
    "low_video_features = []\n",
    "high_video_features = []\n",
    "video_labels = []\n",
    "labels = []\n",
    "frame2video_id = [] # 记录frame属于哪个video\n",
    "# 记录原本有多少条记录\n",
    "face_count = 0\n",
    "pose_count = 0\n",
    "# 记录读入的记录\n",
    "rface_count = 0\n",
    "rpose_count = 0\n",
    "\n",
    "# for each video\n",
    "for i in range(1,len(label)):\n",
    "    directory = label.iloc[i, 0]\n",
    "    frame_features = []\n",
    "    # VCAM number\n",
    "    Date = directory.split('/')[0] # 15YS_20230317_01\n",
    "    Vcam = directory.split('/')[-1]  # VCAM_xxxx_xx\n",
    "    VcamID = Vcam.split('_')[1] # xxxx\n",
    "\n",
    "    # reconstruct the correct Openpose directory\n",
    "    video_directory = os.path.join('siblings_pose', Date,'VCAM_'+VcamID, Vcam)\n",
    "    json_directory = os.path.join(video_directory, 'json')\n",
    "\n",
    "    json_files = os.listdir(json_directory)\n",
    "    json_files.sort(key=lambda x: int(x.split('_')[2])) # sort by the frame id\n",
    "    \n",
    "\n",
    "    # the correct Openface csv file\n",
    "    # feature_file = os.path.join('siblings_face', directory + '.csv')\n",
    "    feature_file = os.path.join('siblings_face_1024', Vcam + '.csv')\n",
    "\n",
    "\n",
    "    # the label data for this video\n",
    "    label_value = label.iloc[i, 1:5] # 取1-4位的标签\n",
    "    video_id = i # video id\n",
    "\n",
    "    # Load face data of a video\n",
    "    try:\n",
    "        face_csv_data = pd.read_csv(feature_file)\n",
    "    except:\n",
    "        print(f\"[face error]: {feature_file} not exist\")\n",
    "        continue\n",
    "    \n",
    "    # log the num of face data rows\n",
    "    face_count += face_csv_data.shape[0]\n",
    "\n",
    "    # 丢弃置信度小于0.5的数据\n",
    "    face_csv_data = face_csv_data[face_csv_data['confidence'] >= confidence_threshold]\n",
    "\n",
    "    # TODO 丢弃 success = 0 的数据\n",
    "    face_csv_data = face_csv_data[face_csv_data['success'] ==1]\n",
    "\n",
    "    # 找到frame中有多于2个不同face_id的帧\n",
    "    counts = face_csv_data.groupby('frame')['face_id'].nunique()\n",
    "    frames_to_drop = counts[counts > 2].index.tolist()\n",
    "\n",
    "    \n",
    "    # 对于每个需要处理的帧，删除置信度最低的行，直到只剩下2个face_id\n",
    "    for frame in frames_to_drop:\n",
    "        frame_df = face_csv_data[face_csv_data['frame'] == frame]\n",
    "        while frame_df['face_id'].nunique() > 2:\n",
    "            min_confidence = frame_df['confidence'].min()\n",
    "            rows_to_drop = frame_df[(frame_df['confidence'] == min_confidence)]['face_id'].tolist()\n",
    "            frame_df = frame_df[~frame_df['face_id'].isin(rows_to_drop)]\n",
    "        face_csv_data = face_csv_data[face_csv_data['frame'] != frame]\n",
    "        face_csv_data = pd.concat([face_csv_data, frame_df], ignore_index=True)\n",
    "\n",
    "    # 丢弃只有1个face_id的帧 \n",
    "    # TODO 是否可以不丢弃？\n",
    "    face_csv_data = face_csv_data.groupby('frame').filter(lambda x: len(x) == 2)\n",
    "\n",
    "\n",
    "    # 按照frame分组，并根据x_30(nose x位置)的大小对face_id进行赋值 x较小标记为0\n",
    "    def assign_face_id(group):\n",
    "        if len(group) != 2:\n",
    "            return None\n",
    "        else:\n",
    "            if group['x_30'].iloc[0] < group['x_30'].iloc[1]:\n",
    "                group['face_id'] = [0, 1]\n",
    "            else:\n",
    "                group['face_id'] = [1, 0]\n",
    "            return group\n",
    "\n",
    "    face_csv_data = face_csv_data.groupby('frame').apply(assign_face_id).reset_index(drop=True)\n",
    "    # # 重新排序\n",
    "    # face_csv_data= face_csv_data.set_index(['face_id', 'frame'])\n",
    "\n",
    "    # def sort_by_frame(group):\n",
    "    #     return group.sort_values(by='frame')\n",
    "\n",
    "    # face_csv_data = face_csv_data.groupby('face_id').apply(sort_by_frame)\n",
    "\n",
    "\n",
    "    # 将df根据face_id列分成两个DataFrame对象\n",
    "    face_df0 = face_csv_data[face_csv_data['face_id'] == 0]\n",
    "    face_df1 = face_csv_data[face_csv_data['face_id'] == 1]\n",
    "\n",
    "    # 按照frame_id列进行排序\n",
    "    # face_df0 = face_df0.sort_values(by='frame')\n",
    "    # face_df1 = face_df1.sort_values(by='frame')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 将df的索引设置为frame_id,并且插值\n",
    "    try:\n",
    "        min_fm, max_fm = face_df0['frame'].min(), face_df0['frame'].max()\n",
    "        if(max_fm - min_fm >2):\n",
    "            # 记录contribute 数据数量\n",
    "            rface_count += 2*face_df0.shape[0]\n",
    "            # 插值\n",
    "            face_df0 = face_df0.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "            face_df1 = face_df1.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "        else:\n",
    "            print(f\"[face error] in {feature_file}: not enough frames\")\n",
    "            # print(f\"len:{len(face_df0)} and {len(face_df1)}\")\n",
    "            continue\n",
    "    except:\n",
    "        print(f\"[face error] in {feature_file}:unknown error in interpolation and reindex\")\n",
    "        continue\n",
    "    # # 对df进行插值\n",
    "    #  face_df0.reset_index()\n",
    "    \n",
    "    ###############  face low feature #######################\n",
    "    # low level feat to cal vel and acc\n",
    "    face_low_feat = ['pose_Tx', 'pose_Ty', 'pose_Tz','pose_Rx', 'pose_Ry', 'pose_Rz', 'gaze_angle_x', 'gaze_angle_y']\n",
    "    au_feat = ['AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU15_r',  'AU20_r', 'AU23_r', 'AU26_r']\n",
    "    \n",
    "\n",
    "    # 每个人的low feat 的 vel and acc\n",
    "    v_mean_0, v_var_0, a_mean_0, a_var_0 = get_vel_and_acc(face_df0[face_low_feat])\n",
    "    v_mean_1, v_var_1, a_mean_1, a_var_1 = get_vel_and_acc(face_df1[face_low_feat])\n",
    "    au_mean_0 = np.array(face_df0[au_feat].mean())\n",
    "    au_mean_1 = np.array(face_df1[au_feat].mean())  \n",
    "    au_var_0 = np.array(face_df0[au_feat].var())\n",
    "    au_var_1 = np.array(face_df1[au_feat].var())\n",
    "\n",
    "\n",
    "    # 每一frame的 face feature\n",
    "    # features_face = face_csv_data.values \n",
    "    low_features_face_0 = np.concatenate((v_mean_0, v_var_0, a_mean_0, a_var_0,au_mean_0,au_var_0))\n",
    "    low_features_face_1 = np.concatenate((v_mean_1, v_var_1, a_mean_1, a_var_1,au_mean_1,au_var_1))\n",
    "\n",
    "    ###############  face high feature #######################\n",
    "\n",
    "    # @1 gaze_angle -> indicating gaze direction\n",
    "    gaze_angle_0 = np.array(face_df0[['gaze_angle_x','gaze_angle_y']])\n",
    "    gaze_angle_1 = np.array(face_df1[['gaze_angle_x','gaze_angle_y']])\n",
    "\n",
    "    gaze_mean_0 = gaze_angle_0.mean(axis=0)\n",
    "    gaze_mean_1 = gaze_angle_1.mean(axis=0) \n",
    "    gaze_var_0 = gaze_angle_0.var(axis=0)\n",
    "    gaze_var_1 = gaze_angle_0.var(axis=0)\n",
    "\n",
    "\n",
    "    # @2 计算两个人之间的角度夹角\n",
    "    # gaze_diff_x = face_df0['gaze_angle_x'] - face_df1['gaze_angle_x']\n",
    "    # gaze_diff_y = face_df0['gaze_angle_y'] - face_df1['gaze_angle_y']\n",
    "\n",
    "    cos_angles = np.sum(gaze_angle_0 * gaze_angle_1, axis=1) / (np.linalg.norm(gaze_angle_0, axis=1) * np.linalg.norm(gaze_angle_1, axis=1))\n",
    "    angles = np.arccos(cos_angles)\n",
    "    # 将弧度值转换为角度值\n",
    "    gaze_angles = np.degrees(angles)\n",
    "\n",
    "    gaze_angle_mean = gaze_angles.mean(axis=0)\n",
    "    gaze_angle_var = gaze_angles.var(axis=0) \n",
    "    v_mean_ga, v_var_ga, a_mean_ga, a_var_ga = get_vel_and_acc(gaze_angles)\n",
    "    # 单个数值合并成 array\n",
    "    gaze_feat = np.array([gaze_angle_mean, gaze_angle_var, v_mean_ga, v_var_ga, a_mean_ga, a_var_ga])\n",
    "\n",
    "\n",
    "    # @3 Motion synchronization -> abs\n",
    "    v_mean_ms, v_var_ms, a_mean_ms, a_var_ms = get_vel_and_acc((face_df0[face_low_feat] - face_df1[face_low_feat]).abs())\n",
    "\n",
    "\n",
    "    # 每一frame的 face feature\n",
    "    # features_face = face_csv_data.values \n",
    "    high_features_face = np.concatenate((gaze_mean_0, gaze_mean_1, gaze_var_0, gaze_var_1, \\\n",
    "                                         gaze_feat,\n",
    "                                         v_mean_ms, v_var_ms, a_mean_ms, a_var_ms\n",
    "                                        ))\n",
    "\n",
    "\n",
    "    ###############  pose feature #######################\n",
    "    \n",
    "    \n",
    "    pose_json_data = [] # save all frame data\n",
    "\n",
    "    # feature names in 'pose_keypoints_2d' in json file\n",
    "    col_name = [\n",
    "        'frame','face_id',\n",
    "       'x0', 'y0', 'c0', 'x1', 'y1', 'c1', 'x2', 'y2', 'c2', 'x3', 'y3', 'c3', 'x4', 'y4', 'c4',\n",
    "       'x5', 'y5', 'c5', 'x6', 'y6', 'c6', 'x7', 'y7', 'c7', 'x8', 'y8', 'c8',\n",
    "       'x9', 'y9', 'c9', 'x10', 'y10', 'c10', 'x11', 'y11', 'c11', 'x12', 'y12', 'c12',\n",
    "       'x13', 'y13', 'c13', 'x14', 'y14', 'c14', 'x15', 'y15', 'c15', 'x16', 'y16', 'c16', \n",
    "       'x17', 'y17', 'c17', 'x18', 'y18', 'c18', 'x19', 'y19', 'c19', 'x20', 'y20', 'c20', \n",
    "       'x21', 'y21', 'c21', 'x22', 'y22', 'c22', 'x23', 'y23', 'c23', 'x24', 'y24', 'c24'\n",
    "       ]\n",
    "\n",
    "    # 创建空的 dataframe\n",
    "    pose_df0 = pd.DataFrame(columns=col_name)\n",
    "    pose_df1 = pd.DataFrame(columns=col_name)\n",
    "    \n",
    "    \n",
    "    # Load pose data of a video frame\n",
    "    for file in json_files: # for a single frame\n",
    "        file_path = os.path.join(json_directory, file)\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "        except:\n",
    "            print(f\"[pose error]: {file} not exist\")\n",
    "            continue\n",
    "\n",
    "        # log the number\n",
    "        pose_count += len(data['people'])\n",
    "        \n",
    "        # 漏检测 只有1人的情况\n",
    "        if len(data['people']) != 2:\n",
    "            # drop this frame\n",
    "            continue\n",
    "        \n",
    "        row0 = data['people'][0]['pose_keypoints_2d'] # x0,y0,c0,x1,y1,c1,... x24,y24,c24\n",
    "        row1 = data['people'][1]['pose_keypoints_2d']\n",
    "\n",
    "        # face_id对应 x较小 标记为0，x较大 标记为1 \n",
    "        if(row0[0]>row1[0]):\n",
    "            row0,row1 = row1,row0 # swap\n",
    "\n",
    "        # 插入face_id\n",
    "        # TODO del face_id no need anymore\n",
    "        row0.insert(0,0)\n",
    "        row1.insert(0,1)\n",
    "\n",
    "        # 插入frame\n",
    "        frame_id = int(file.split('_')[-2]) # 文件 frame_id\n",
    "\n",
    "        # 去掉多余的最后一 frame 文件 否者会导致 frame 重复\n",
    "        if frame_id % 5 != 0:\n",
    "            continue\n",
    "\n",
    "        frame_id = frame_id // 5 + 1 # 恢复frame id 抽帧后的 id\n",
    "        row0.insert(0,frame_id)\n",
    "        row1.insert(0,frame_id)\n",
    "\n",
    "        pose_df0.loc[len(pose_df0)] = row0\n",
    "        pose_df1.loc[len(pose_df1)] = row1\n",
    "\n",
    "     # 将df的索引设置为frame_id,并且插值\n",
    "    try:\n",
    "        # set frame to int type\n",
    "        pose_df0['frame'] = pose_df0['frame'].astype(int)\n",
    "        pose_df1['frame'] = pose_df1['frame'].astype(int)\n",
    "        min_fm, max_fm = pose_df0['frame'].min(), pose_df0['frame'].max()\n",
    "\n",
    "        if(max_fm - min_fm >2):\n",
    "            # 记录contribute 数据数量\n",
    "            rpose_count += 2*pose_df0.shape[0]\n",
    "            # 插值\n",
    "            pose_df0 = pose_df0.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "            pose_df1 = pose_df1.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "        else:\n",
    "            print(f\"[pose error] in {feature_file}: not enough frames\")\n",
    "            # print(f\"len:{len(face_df0)} and {len(face_df1)}\")\n",
    "            continue\n",
    "    except:\n",
    "        print(f\"[pose error] in {feature_file}:unknown error in interpolation and reindex\")\n",
    "        continue\n",
    "\n",
    "    ###############  pose low feature #######################\n",
    "    \n",
    "    # TODO select low feat\n",
    "    # pose_low_feat = ['x','y']\n",
    "    pose_low_feat = col_name[2:]\n",
    "    pose_low_feat = [col for col in pose_low_feat if not col.startswith('c')] # filter all confidence\n",
    "\n",
    "    # 每个人的low feat 的 vel and acc\n",
    "    v_mean_0, v_var_0, a_mean_0, a_var_0 = get_vel_and_acc(pose_df0[pose_low_feat])\n",
    "    v_mean_1, v_var_1, a_mean_1, a_var_1 = get_vel_and_acc(pose_df1[pose_low_feat])\n",
    "    mean_0 = np.array(pose_df0[pose_low_feat].mean())\n",
    "    mean_1 = np.array(pose_df1[pose_low_feat].mean())\n",
    "    var_0 = np.array(pose_df0[pose_low_feat].var())\n",
    "    var_1 = np.array(pose_df1[pose_low_feat].var())\n",
    "    \n",
    "\n",
    "    ###############  pose high feature #######################\n",
    "    # TODO pose high feature\n",
    "\n",
    "    # left and right shoulder distance → (mean + var) = 2\n",
    "    # hands-to-face distance (left, right) → (mean + var) = 4\n",
    "\n",
    "\n",
    "\n",
    "    # features_pose = np.array(pose_json_data)\n",
    "    low_features_pose_0 = np.concatenate((v_mean_0, v_var_0, a_mean_0, a_var_0,mean_0,var_0))\n",
    "    low_features_pose_1 = np.concatenate((v_mean_1, v_var_1, a_mean_1, a_var_1,mean_1,var_1))\n",
    "\n",
    "    # 将记录视频特征\n",
    "    low_video_features.append(np.concatenate((low_features_face_0, low_features_pose_0, low_features_face_1, low_features_pose_1))) # simply attach them all together\n",
    "    high_video_features.append(np.concatenate((high_features_face, low_features_face_0, low_features_pose_0, low_features_face_1, low_features_pose_1)))\n",
    "\n",
    "\n",
    "    # video 级别label\n",
    "    video_labels.append(np.argmax(label_value.astype(\"int\"),axis=0)) # one-hot to class id\n",
    "    \n",
    "    # # frame级别label\n",
    "    # video_labels.append(np.array(labels))\n",
    "\n",
    "X_low = low_video_features\n",
    "X_high = high_video_features\n",
    "y = video_labels\n",
    "\n",
    "\n",
    "# 总共遍历的face特征和pose特征数\n",
    "print(f\"Total face feat:{face_count}, pose feat:{pose_count}\")\n",
    "# 读入的数量\n",
    "print(f\"Read in videos X:{len(X)}, face_feat:{rface_count},pose_feat:{rpose_count}\")\n",
    "# # drop\n",
    "print(f\"Drop {face_count - rface_count} face features, {pose_count - rpose_count} pose features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = high_video_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=0, arr=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in videos y:624\n"
     ]
    }
   ],
   "source": [
    "print(f\"Read in videos y:{len(y)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:746\n"
     ]
    }
   ],
   "source": [
    "print(f\"X:{len(X[0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video num: X_train:499, X_test:125, y_train:499, y_test:125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# frame split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, random_state=42)\n",
    "print(f\"Video num: X_train:{len(X_train)}, X_test:{len(X_test)}, y_train:{len(y_train)}, y_test:{len(y_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation  \n",
    "- 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score\n",
    "\n",
    "def crossVal(rfc, X, y):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#             'f1': make_scorer(f1_score, average='weighted'),\n",
    "#             'recall': make_scorer(recall_score, average='weighted')}\n",
    "\n",
    "    scoring = ['accuracy', 'f1_weighted', 'recall_weighted', 'precision_weighted']\n",
    "\n",
    "    # 使用交叉验证器对模型进行评估\n",
    "    scores = cross_validate(rfc, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "    # 输出交叉验证结果\n",
    "    print('Accuracy:', scores['test_accuracy'].mean())\n",
    "    print('F1 score:', scores['test_f1_weighted'].mean())\n",
    "    print('Recall:', scores['test_recall_weighted'].mean())\n",
    "    print('Precision:', scores['test_precision_weighted'].mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.52      0.72      0.60        39\n",
      "           中       0.50      0.11      0.17        19\n",
      "           弱       0.53      0.45      0.49        38\n",
      "    没有回应（忽视）       0.43      0.52      0.47        29\n",
      "\n",
      "    accuracy                           0.50       125\n",
      "   macro avg       0.49      0.45      0.43       125\n",
      "weighted avg       0.50      0.50      0.47       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 使用随机森林预测一个frame\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_predict = rfc.predict(X_test)\n",
    "\n",
    "print(f\"acc:{rfc.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45345806451612897\n",
      "F1 score: 0.40893686350792535\n",
      "Recall: 0.45345806451612897\n",
      "Precision: 0.4022042028898019\n"
     ]
    }
   ],
   "source": [
    "crossVal(rfc,X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"强：{len(y[y==0])}, 中：{len(y[y==1])}, 弱：{len(y[y==2])}, 没有回应（忽视）：{len(y[y==3])}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 建立决策树分类器\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_predict = clf.predict(X_test)\n",
    "\n",
    "# print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "# print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35907096774193553\n",
      "F1 score: 0.3549327998522269\n",
      "Recall: 0.35907096774193553\n",
      "Precision: 0.3589581231396566\n"
     ]
    }
   ],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 建立KNN分类器\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_predict = clf.predict(X_test)\n",
    "\n",
    "# print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "# print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3189032258064516\n",
      "F1 score: 0.3065399857800289\n",
      "Recall: 0.3189032258064516\n",
      "Precision: 0.3245333584546152\n"
     ]
    }
   ],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "结果很差 看warning原因应该是有一些结果直接没有分类  \n",
    "看看是否需要调参数或者直接去掉 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.40      0.62      0.48        39\n",
      "           中       0.00      0.00      0.00        19\n",
      "           弱       0.43      0.32      0.36        38\n",
      "    没有回应（忽视）       0.43      0.55      0.48        29\n",
      "\n",
      "    accuracy                           0.42       125\n",
      "   macro avg       0.32      0.37      0.33       125\n",
      "weighted avg       0.36      0.42      0.37       125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# clf = SVC(kernel='linear')\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3733161290322581\n",
      "F1 score: 0.3331413623531893\n",
      "Recall: 0.3733161290322581\n",
      "Precision: 0.31028633793320354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.51      0.62      0.56        39\n",
      "           中       0.17      0.05      0.08        19\n",
      "           弱       0.47      0.53      0.49        38\n",
      "    没有回应（忽视）       0.52      0.52      0.52        29\n",
      "\n",
      "    accuracy                           0.48       125\n",
      "   macro avg       0.41      0.43      0.41       125\n",
      "weighted avg       0.45      0.48      0.46       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# 定义模型参数\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 4,\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "# 将数据转换为DMatrix格式\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# 训练模型\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# 在测试集上预测\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.432658064516129\n",
      "F1 score: 0.40997846722685444\n",
      "Recall: 0.432658064516129\n",
      "Precision: 0.41474823524613236\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 定义xgboost分类器模型\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "crossVal(xgb,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM  \n",
    "not working so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 4) # 4 classes\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out, _ = self.lstm(x) # 1 * 100\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "        \n",
    "class mil_regression(nn.Module):\n",
    "    def __init__(self, input_size=786, hidden_size=100, num_layers=1, output_size=1):\n",
    "        ''' use LSTM for MIL '''\n",
    "        super(mil_regression, self).__init__()\n",
    "        self.net = LSTM(input_size, hidden_size, num_layers)\n",
    "        self.class_num = output_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input shape: (frame_num, feature_size)\n",
    "        \n",
    "\n",
    "        self.seg_num, self.feature_num = inputs.shape #\n",
    "\n",
    "        # outputs = torch.zeros((self.seg_num, self.class_num)).double.cuda() #  frame * 4（bool）\n",
    "\n",
    "        outputs = self.net(inputs)\n",
    "        # for i in range(self.seg_num):\n",
    "        #     outputs[i,:] = self.net(inputs[i]) # 786\n",
    "\n",
    "        # for idx, seg in enumerate(inputs):\n",
    "        #     seg = Variable(seg).cuda()\n",
    "        #     outputs[idx] = self.net(seg)\n",
    "\n",
    "        # 视频特征 = frame取平均\n",
    "        output = torch.mean(outputs, 1).cuda()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "model = mil_regression().cuda()\n",
    "\n",
    "epochs = 150\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X_train)): # 每次处理一个视频(对batch)\n",
    "\n",
    "        x = torch.tensor(X_train[i]).float().cuda()\n",
    "        y = torch.tensor(y_train[i]).float().cuda()\n",
    "        \n",
    "\n",
    "        if len(x.shape) ==1:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x)\n",
    "\n",
    "        single_loss = loss_function(y_pred, y)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if (i+1) % 10 == 0:\n",
    "        #     print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, len(X_train), single_loss.item()))\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(X_test)): # 每次处理一个视频(对batch)\n",
    "        x = torch.tensor(X_test[i]).float().cuda()\n",
    "        y = torch.tensor(y_test[i]).float().cuda()\n",
    "        print(y)\n",
    "\n",
    "        if len(x.shape) ==1:\n",
    "            continue\n",
    "\n",
    "        outputs = model(x)\n",
    "        print(outputs)\n",
    "        correct += (outputs == y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3. ,  3. ,  3. ],\n",
      "       [ 2. ,  3. , 48.5],\n",
      "       [ 0.5,  1.5, 47. ],\n",
      "       [ 0. ,  0. ,  0. ]]), array([[ 1. ,  1. ,  1. ],\n",
      "       [ 1. ,  1. ,  1. ],\n",
      "       [ 3. , 47.5, 92. ],\n",
      "       [ 3. , 47.5, 92. ]])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维矩阵\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [5, 8, 100],[5, 8, 100]])\n",
    "\n",
    "# 计算梯度\n",
    "dy = np.gradient(x)\n",
    "\n",
    "# 输出结果\n",
    "print(dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([nan, nan])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162420/1742590338.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  d2x.append(np.diff(dx2-dx1) / np.diff(dx3-dx2))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维数组\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算每一行相邻行之间的二阶导数\n",
    "d2x = []\n",
    "for i in range(1, x.shape[0]-1):\n",
    "    dx1 = np.gradient(x[i-1, :])\n",
    "    dx2 = np.gradient(x[i, :])\n",
    "    dx3 = np.gradient(x[i+1, :])\n",
    "    d2x.append(np.diff(dx2-dx1) / np.diff(dx3-dx2))\n",
    "\n",
    "# 输出结果\n",
    "print(d2x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 1.]), array([1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维数组\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算每一行数据对上一行数据的导数\n",
    "dx = []\n",
    "for i in range(1, x.shape[0]):\n",
    "    diff = np.diff(x[i, :]) / np.diff(x[i-1, :])\n",
    "    dx.append(diff)\n",
    "\n",
    "# 输出结果\n",
    "print(dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame  feature\n",
      "0      1      1.0\n",
      "1      2      3.0\n",
      "2      3      5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设df是一个DataFrame对象，其中包含frame和feature两列\n",
    "df = pd.DataFrame({'frame': [1, 3], 'feature': [1, 5]})\n",
    "\n",
    "# 将df的索引设置为frame列，并增加需要插值的索引值\n",
    "df = df.set_index('frame').reindex(range(df['frame'].min(), df['frame'].max()+1))\n",
    "\n",
    "# 对df进行插值\n",
    "df_interpolated = df.interpolate().reset_index()\n",
    "\n",
    "# 输出插值结果\n",
    "print(df_interpolated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

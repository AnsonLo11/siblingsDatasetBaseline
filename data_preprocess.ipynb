{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要分别读入face和pose的数据并对应起来\n",
    "- 对于siblings_face 需要读入json  \n",
    "- 对于siblings_pose 需要读入csv    \n",
    "- 对于Label 需要读入csv\n",
    "\n",
    "\n",
    "*特别注意对于face，需要去除置信度小于阈值的数据  \n",
    "*要将video的label扩展到每个frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 读取标签文件\n",
    "label = pd.read_csv('labelA/回应情况-表格 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>切片ID</th>\n",
       "      <th>回应情况</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>强</td>\n",
       "      <td>中</td>\n",
       "      <td>弱</td>\n",
       "      <td>没有回应（忽视）</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15YS_20230317_01/VCAM_0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15YS_20230317_01/VCAM_0000_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15YS_20230317_01/VCAM_0000_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15YS_20230317_01/VCAM_0000_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           切片ID 回应情况 Unnamed: 2 Unnamed: 3 Unnamed: 4   \n",
       "0                           NaN    强          中          弱   没有回应（忽视）  \\\n",
       "1    15YS_20230317_01/VCAM_0000    0          0          1          0   \n",
       "2  15YS_20230317_01/VCAM_0000_1    0          0          1          0   \n",
       "3  15YS_20230317_01/VCAM_0000_2    1          0          0          0   \n",
       "4  15YS_20230317_01/VCAM_0000_3    0          0          1          0   \n",
       "\n",
       "   Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10   \n",
       "0         NaN         NaN         NaN         NaN         NaN          NaN  \\\n",
       "1         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "\n",
       "   Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15   \n",
       "0          NaN          NaN          NaN          NaN          NaN  \\\n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 16  Unnamed: 17  \n",
       "0          NaN          NaN  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.iloc[1,0][-4:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并读取face和pose特征  \n",
    "按照视频读取frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vel_and_acc(features):\n",
    "    \"\"\"\n",
    "    cal the mean and var of velocity and acceleration respectively of input features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_order_derivatives = np.gradient(features, axis=0)\n",
    "        second_order_derivatives = np.gradient(first_order_derivatives, axis=0)\n",
    "    except:\n",
    "        print(\"Error in get_vel_and_acc\")\n",
    "        print(features.shape)\n",
    "        print(print(f\"len:{len(face_df0)} and {len(face_df1)}\"))\n",
    "        print(max_fm)\n",
    "        print(\"------------------\")\n",
    "\n",
    "    # velecity\n",
    "    vel_means = np.mean(first_order_derivatives, axis=0)\n",
    "    vel_var = np.var(first_order_derivatives, axis=0)\n",
    "\n",
    "    # acceleration\n",
    "    acc_means = np.mean(second_order_derivatives, axis=0)\n",
    "    acc_var = np.var(second_order_derivatives, axis=0)\n",
    "    \n",
    "    return vel_means, vel_var, acc_means, acc_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[face error]: siblings_face/15YS_20230317_01/VCAM_0000_3.csv not exist\n",
      "[face error]: siblings_face/15YS_20230317_01/VCAM_0000_37.csv not exist\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_58.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_59.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_78.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_79.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_80.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_94.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_95.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_97.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_98.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0000_99.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_3.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_5.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_6.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_7.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_8.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_14.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_15.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_16.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_17.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_26.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_27.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_28.csv: not enough frames\n",
      "[face error]: siblings_face/15YS_20230317_01/VCAM_0001_29.csv not exist\n",
      "[face error]: siblings_face/15YS_20230317_01/VCAM_0001_30.csv not exist\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_31.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_32.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_33.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_34.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_35.csv: not enough frames\n",
      "[face error]: siblings_face/15YS_20230317_01/VCAM_0001_37.csv not exist\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_44.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_45.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_46.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_47.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_48.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_51.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_52.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_53.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_54.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_55.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_56.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_61.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_67.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_69.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_76.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_77.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_89.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0001_93.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_1.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_2.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_8.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_9.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_10.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_11.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_12.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_13.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_14.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_17.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_18.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_19.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_20.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_23.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_24.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_25.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_26.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_27.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_28.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_29.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_32.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_33.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_36.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_38.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_43.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_44.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_46.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_47.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_50.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_51.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_52.csv: not enough frames\n",
      "[face error]: siblings_face/15YS_20230317_01/VCAM_0002_53.csv not exist\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_55.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_59.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_65.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_68.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_69.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_70.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_71.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_72.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_74.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_75.csv: not enough frames\n",
      "[face error]: siblings_face/15YS_20230317_01/VCAM_0002_76.csv not exist\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_77.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_85.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_89.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_90.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_97.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0002_98.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_1.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_8.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_19.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_39.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_42.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_50.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_52.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_55.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_56.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_63.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_64.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_72.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_78.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_81.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_86.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_87.csv: not enough frames\n",
      "[face error]: siblings_face/15YS_20230317_01/VCAM_0003_89.csv not exist\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_91.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_97.csv: not enough frames\n",
      "[face error] in siblings_face/15YS_20230317_01/VCAM_0003_98.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_2.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_11.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_14.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_15.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_16.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_18.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_24.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_28.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_29.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_30.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_61.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_74.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_75.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_78.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_79.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_80.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_82.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_94.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_97.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_102.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_103.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_104.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_105.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_106.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_108.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_110.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_116.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_117.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_118.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_119.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_125.csv: not enough frames\n",
      "[face error]: siblings_face/16YS_20230317_01/VCAM_0004_126.csv not exist\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_129.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_139.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_143.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_144.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_148.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_149.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_150.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_151.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_152.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_153.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_154.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_158.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_159.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_160.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_162.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_163.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_164.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_169.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_172.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0004_177.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_1.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_6.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_11.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_15.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_16.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_22.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_25.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_26.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_29.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_33.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_34.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_35.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_36.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_37.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_38.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_39.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_40.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_44.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_45.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_46.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_48.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_50.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_51.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_53.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_54.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_56.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_57.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_61.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_62.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_65.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_66.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_68.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_69.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_70.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_71.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_74.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_75.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_76.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_84.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_87.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_88.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_89.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_90.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_91.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_96.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_97.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_99.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_100.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_101.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_102.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_103.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_104.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_105.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_106.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_111.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_114.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_115.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_116.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_119.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_120.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_122.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_123.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_124.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_125.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_127.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_128.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_139.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_140.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_148.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_151.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_152.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_158.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0005_162.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_1.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_5.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_6.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_7.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_8.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_11.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_12.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_13.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_16.csv: not enough frames\n",
      "[face error]: siblings_face/16YS_20230317_01/VCAM_0006_18.csv not exist\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_19.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_22.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_23.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_29.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_33.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_34.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_46.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_48.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_52.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_65.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_70.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_72.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_73.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_74.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_75.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_77.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_78.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_80.csv: not enough frames\n",
      "[face error]: siblings_face/16YS_20230317_01/VCAM_0006_81.csv not exist\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_85.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_88.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_89.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_90.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_92.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_96.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_98.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_99.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_100.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_101.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_102.csv: not enough frames\n",
      "[face error]: siblings_face/16YS_20230317_01/VCAM_0006_103.csv not exist\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_105.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_107.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_111.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_113.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_114.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_115.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_116.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_117.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_119.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_120.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_121.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_122.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_124.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_130.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_131.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_134.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_135.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_137.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_138.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_139.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_141.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0006_142.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_1.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_2.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_3.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_4.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_5.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_6.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_7.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_8.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_9.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_10.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_11.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_12.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_22.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_23.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_26.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_30.csv: not enough frames\n",
      "[face error] in siblings_face/16YS_20230317_01/VCAM_0007_32.csv: not enough frames\n",
      "Total face feat:42236, pose feat:33612\n",
      "Read in videos X:544, face_feat:11442,pose_feat:33372\n",
      "Drop 30794 face features, 240 pose features\n"
     ]
    }
   ],
   "source": [
    "# set openface confidence threshold\n",
    "confidence_threshold = 0.1\n",
    "\n",
    "# 导入特征并对齐标签\n",
    "video_features = []\n",
    "video_labels = []\n",
    "labels = []\n",
    "frame2video_id = [] # 记录frame属于哪个video\n",
    "# 记录原本有多少条记录\n",
    "face_count = 0\n",
    "pose_count = 0\n",
    "# 记录读入的记录\n",
    "rface_count = 0\n",
    "rpose_count = 0\n",
    "\n",
    "# for each video\n",
    "for i in range(1,len(label)):\n",
    "    directory = label.iloc[i, 0]\n",
    "    frame_features = []\n",
    "    # VCAM number\n",
    "    Date = directory.split('/')[0] # 15YS_20230317_01\n",
    "    Vcam = directory.split('/')[-1]  # VCAM_xxxx_xx\n",
    "    VcamID = Vcam.split('_')[1] # xxxx\n",
    "\n",
    "    # reconstruct the correct Openpose directory\n",
    "    video_directory = os.path.join('siblings_pose', Date,'VCAM_'+VcamID, Vcam)\n",
    "    json_directory = os.path.join(video_directory, 'json')\n",
    "\n",
    "    json_files = os.listdir(json_directory)\n",
    "    json_files.sort(key=lambda x: int(x.split('_')[2])) # sort by the frame id\n",
    "    \n",
    "\n",
    "    # the correct Openface csv file\n",
    "    feature_file = os.path.join('siblings_face', directory + '.csv')\n",
    "\n",
    "    # the label data for this video\n",
    "    label_value = label.iloc[i, 1:5] # 取1-4位的标签\n",
    "    video_id = i # video id\n",
    "\n",
    "    # Load face data of a video\n",
    "    try:\n",
    "        face_csv_data = pd.read_csv(feature_file)\n",
    "    except:\n",
    "        print(f\"[face error]: {feature_file} not exist\")\n",
    "        continue\n",
    "    \n",
    "    # log the num of face data rows\n",
    "    face_count += face_csv_data.shape[0]\n",
    "\n",
    "    # 丢弃置信度小于0.5的数据\n",
    "    face_csv_data = face_csv_data[face_csv_data['confidence'] >= confidence_threshold]\n",
    "\n",
    "    # 找到frame中有多于2个不同face_id的帧\n",
    "    counts = face_csv_data.groupby('frame')['face_id'].nunique()\n",
    "    frames_to_drop = counts[counts > 2].index.tolist()\n",
    "\n",
    "    \n",
    "    # 对于每个需要处理的帧，删除置信度最低的行，直到只剩下2个face_id\n",
    "    for frame in frames_to_drop:\n",
    "        frame_df = face_csv_data[face_csv_data['frame'] == frame]\n",
    "        while frame_df['face_id'].nunique() > 2:\n",
    "            min_confidence = frame_df['confidence'].min()\n",
    "            rows_to_drop = frame_df[(frame_df['confidence'] == min_confidence)]['face_id'].tolist()\n",
    "            frame_df = frame_df[~frame_df['face_id'].isin(rows_to_drop)]\n",
    "        face_csv_data = face_csv_data[face_csv_data['frame'] != frame]\n",
    "        face_csv_data = pd.concat([face_csv_data, frame_df], ignore_index=True)\n",
    "\n",
    "    # 丢弃只有1个face_id的帧 \n",
    "    # TODO 是否可以不丢弃？\n",
    "    face_csv_data = face_csv_data.groupby('frame').filter(lambda x: len(x) == 2)\n",
    "\n",
    "\n",
    "    # 按照frame分组，并根据x_30(nose x位置)的大小对face_id进行赋值 x较小标记为0\n",
    "    def assign_face_id(group):\n",
    "        if len(group) != 2:\n",
    "            return None\n",
    "        else:\n",
    "            if group['x_30'].iloc[0] < group['x_30'].iloc[1]:\n",
    "                group['face_id'] = [0, 1]\n",
    "            else:\n",
    "                group['face_id'] = [1, 0]\n",
    "            return group\n",
    "\n",
    "    face_csv_data = face_csv_data.groupby('frame').apply(assign_face_id).reset_index(drop=True)\n",
    "    # # 重新排序\n",
    "    # face_csv_data= face_csv_data.set_index(['face_id', 'frame'])\n",
    "\n",
    "    # def sort_by_frame(group):\n",
    "    #     return group.sort_values(by='frame')\n",
    "\n",
    "    # face_csv_data = face_csv_data.groupby('face_id').apply(sort_by_frame)\n",
    "\n",
    "\n",
    "    # 将df根据face_id列分成两个DataFrame对象\n",
    "    face_df0 = face_csv_data[face_csv_data['face_id'] == 0]\n",
    "    face_df1 = face_csv_data[face_csv_data['face_id'] == 1]\n",
    "\n",
    "    # 按照frame_id列进行排序\n",
    "    # face_df0 = face_df0.sort_values(by='frame')\n",
    "    # face_df1 = face_df1.sort_values(by='frame')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 将df的索引设置为frame_id,并且插值\n",
    "    try:\n",
    "        min_fm, max_fm = face_df0['frame'].min(), face_df0['frame'].max()\n",
    "        if(max_fm - min_fm >2):\n",
    "            # 记录contribute 数据数量\n",
    "            rface_count += 2*face_df0.shape[0]\n",
    "            # 插值\n",
    "            face_df0 = face_df0.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "            face_df1 = face_df1.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "        else:\n",
    "            print(f\"[face error] in {feature_file}: not enough frames\")\n",
    "            # print(f\"len:{len(face_df0)} and {len(face_df1)}\")\n",
    "            continue\n",
    "    except:\n",
    "        print(f\"[face error] in {feature_file}:unknown error in interpolation and reindex\")\n",
    "        continue\n",
    "    # # 对df进行插值\n",
    "    #  face_df0.reset_index()\n",
    "    \n",
    "    ###############  face low feature #######################\n",
    "    # low level feat to cal vel and acc\n",
    "    face_low_feat = ['pose_Tx', 'pose_Ty', 'pose_Tz','pose_Rx', 'pose_Ry', 'pose_Rz', 'gaze_angle_x', 'gaze_angle_y']\n",
    "    au_feat = ['AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU15_r',  'AU20_r', 'AU23_r', 'AU26_r']\n",
    "    \n",
    "\n",
    "    # 每个人的low feat 的 vel and acc\n",
    "    v_mean_0, v_var_0, a_mean_0, a_var_0 = get_vel_and_acc(face_df0[face_low_feat])\n",
    "    v_mean_1, v_var_1, a_mean_1, a_var_1 = get_vel_and_acc(face_df1[face_low_feat])\n",
    "    au_mean_0 = np.array(face_df0[au_feat].mean())\n",
    "    au_mean_1 = np.array(face_df1[au_feat].mean())  \n",
    "    au_var_0 = np.array(face_df0[au_feat].var())\n",
    "    au_var_1 = np.array(face_df1[au_feat].var())\n",
    "\n",
    "    ###############  face high feature #######################\n",
    "    # TODO face high feats\n",
    "\n",
    "\n",
    "    # 每一frame的 face feature\n",
    "    # features_face = face_csv_data.values \n",
    "    features_face_0 = np.concatenate((v_mean_0, v_var_0, a_mean_0, a_var_0,au_mean_0,au_var_0))\n",
    "    features_face_1 = np.concatenate((v_mean_1, v_var_1, a_mean_1, a_var_1,au_mean_1,au_var_1))\n",
    "\n",
    "    \n",
    "    ###############  pose feature #######################\n",
    "    \n",
    "    \n",
    "    pose_json_data = [] # save all frame data\n",
    "\n",
    "    # feature names in 'pose_keypoints_2d' in json file\n",
    "    col_name = [\n",
    "        'frame','face_id',\n",
    "       'x0', 'y0', 'c0', 'x1', 'y1', 'c1', 'x2', 'y2', 'c2', 'x3', 'y3', 'c3', 'x4', 'y4', 'c4',\n",
    "       'x5', 'y5', 'c5', 'x6', 'y6', 'c6', 'x7', 'y7', 'c7', 'x8', 'y8', 'c8',\n",
    "       'x9', 'y9', 'c9', 'x10', 'y10', 'c10', 'x11', 'y11', 'c11', 'x12', 'y12', 'c12',\n",
    "       'x13', 'y13', 'c13', 'x14', 'y14', 'c14', 'x15', 'y15', 'c15', 'x16', 'y16', 'c16', \n",
    "       'x17', 'y17', 'c17', 'x18', 'y18', 'c18', 'x19', 'y19', 'c19', 'x20', 'y20', 'c20', \n",
    "       'x21', 'y21', 'c21', 'x22', 'y22', 'c22', 'x23', 'y23', 'c23', 'x24', 'y24', 'c24'\n",
    "       ]\n",
    "    # 创建空的 dataframe\n",
    "    pose_df0 = pd.DataFrame(columns=col_name)\n",
    "    pose_df1 = pd.DataFrame(columns=col_name)\n",
    "    \n",
    "    \n",
    "    # TODO del confidence as \n",
    "    # Load pose data of a video frame\n",
    "    for file in json_files: # for a single frame\n",
    "        file_path = os.path.join(json_directory, file)\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "        except:\n",
    "            print(f\"[pose error]: {file} not exist\")\n",
    "            continue\n",
    "\n",
    "        # log the number\n",
    "        pose_count += len(data['people'])\n",
    "        \n",
    "        # 漏检测 只有1人的情况\n",
    "        if len(data['people']) != 2:\n",
    "            # drop this frame\n",
    "            continue\n",
    "        \n",
    "        row0 = data['people'][0]['pose_keypoints_2d'] # x0,y0,c0,x1,y1,c1,... x24,y24,c24\n",
    "        row1 = data['people'][1]['pose_keypoints_2d']\n",
    "\n",
    "        # face_id对应 x较小 标记为0，x较大 标记为1 \n",
    "        if(row0[0]>row1[0]):\n",
    "            row0,row1 = row1,row0 # swap\n",
    "\n",
    "        # 插入face_id\n",
    "        # TODO del face_id no need anymore\n",
    "        row0.insert(0,0)\n",
    "        row1.insert(0,1)\n",
    "\n",
    "        # 插入frame\n",
    "        frame_id = int(file.split('_')[-2]) # 文件 frame_id\n",
    "\n",
    "        # 去掉多余的最后一 frame 文件 否者会导致 frame 重复\n",
    "        if frame_id % 5 != 0:\n",
    "            continue\n",
    "\n",
    "        frame_id = frame_id // 5 + 1 # 恢复frame id 抽帧后的 id\n",
    "        row0.insert(0,frame_id)\n",
    "        row1.insert(0,frame_id)\n",
    "\n",
    "        pose_df0.loc[len(pose_df0)] = row0\n",
    "        pose_df1.loc[len(pose_df1)] = row1\n",
    "\n",
    "        # pose_json_data.append(row0)\n",
    "        # pose_json_data.append(row1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "     # 将df的索引设置为frame_id,并且插值\n",
    "    try:\n",
    "        # set frame to int type\n",
    "        pose_df0['frame'] = pose_df0['frame'].astype(int)\n",
    "        pose_df1['frame'] = pose_df1['frame'].astype(int)\n",
    "        min_fm, max_fm = pose_df0['frame'].min(), pose_df0['frame'].max()\n",
    "\n",
    "        if(max_fm - min_fm >2):\n",
    "            # 记录contribute 数据数量\n",
    "            rpose_count += 2*pose_df0.shape[0]\n",
    "            # 插值\n",
    "            pose_df0 = pose_df0.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "            pose_df1 = pose_df1.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "        else:\n",
    "            print(f\"[pose error] in {feature_file}: not enough frames\")\n",
    "            # print(f\"len:{len(face_df0)} and {len(face_df1)}\")\n",
    "            continue\n",
    "    except:\n",
    "        print(f\"[pose error] in {feature_file}:unknown error in interpolation and reindex\")\n",
    "        continue\n",
    "\n",
    "    ###############  pose low feature #######################\n",
    "    \n",
    "    # TODO select low feat\n",
    "    # pose_low_feat = ['x','y']\n",
    "    pose_low_feat = col_name[2:]\n",
    "\n",
    "    # 每个人的low feat 的 vel and acc\n",
    "    # TODO something wrong with 450 feats\n",
    "    v_mean_0, v_var_0, a_mean_0, a_var_0 = get_vel_and_acc(pose_df0[pose_low_feat])\n",
    "    v_mean_1, v_var_1, a_mean_1, a_var_1 = get_vel_and_acc(pose_df1[pose_low_feat])\n",
    "    mean_0 = np.array(pose_df0[pose_low_feat].mean())\n",
    "    mean_1 = np.array(pose_df1[pose_low_feat].mean())\n",
    "    var_0 = np.array(pose_df0[pose_low_feat].var())\n",
    "    var_1 = np.array(pose_df1[pose_low_feat].var())\n",
    "    \n",
    "\n",
    "    ###############  pose high feature #######################\n",
    "    # TODO pose high feature\n",
    "\n",
    "    # left and right shoulder distance → (mean + var) = 2\n",
    "    # hands-to-face distance (left, right) → (mean + var) = 4\n",
    "\n",
    "\n",
    "\n",
    "    # features_pose = np.array(pose_json_data)\n",
    "    features_pose_0 = np.concatenate((v_mean_0, v_var_0, a_mean_0, a_var_0,mean_0,var_0))\n",
    "    features_pose_1 = np.concatenate((v_mean_1, v_var_1, a_mean_1, a_var_1,mean_1,var_1))\n",
    "\n",
    "    # 将记录视频特征\n",
    "    # video_features.append(np.array(frame_features))\n",
    "    video_features.append(np.concatenate((features_face_0,features_pose_0,features_face_1,features_pose_1))) # simply attach them all together\n",
    "    \n",
    "    # video 级别label\n",
    "    video_labels.append(np.argmax(label_value.astype(\"int\"),axis=0)) # one-hot to class id\n",
    "    \n",
    "    # # frame级别label\n",
    "    # video_labels.append(np.array(labels))\n",
    "\n",
    "X = video_features\n",
    "y = video_labels\n",
    "\n",
    "\n",
    "# 总共遍历的face特征和pose特征数\n",
    "print(f\"Total face feat:{face_count}, pose feat:{pose_count}\")\n",
    "# 读入的数量\n",
    "print(f\"Read in videos X:{len(X)}, face_feat:{rface_count},pose_feat:{rpose_count}\")\n",
    "# # drop\n",
    "print(f\"Drop {face_count - rface_count} face features, {pose_count - rpose_count} pose features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in videos y:544\n"
     ]
    }
   ],
   "source": [
    "print(f\"Read in videos y:{len(y)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(X[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "print(f\"X:{len(X[0][0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video num: X_train:435, X_test:109, y_train:435, y_test:109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# frame split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Video num: X_train:{len(X_train)}, X_test:{len(X_test)}, y_train:{len(y_train)}, y_test:{len(y_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation  \n",
    "- 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score\n",
    "\n",
    "def crossVal(rfc, X, y):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#             'f1': make_scorer(f1_score, average='weighted'),\n",
    "#             'recall': make_scorer(recall_score, average='weighted')}\n",
    "\n",
    "    scoring = ['accuracy', 'f1_weighted', 'recall_weighted', 'precision_weighted']\n",
    "\n",
    "    # 使用交叉验证器对模型进行评估\n",
    "    scores = cross_validate(rfc, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "    # 输出交叉验证结果\n",
    "    print('Accuracy:', scores['test_accuracy'].mean())\n",
    "    print('F1 score:', scores['test_f1_weighted'].mean())\n",
    "    print('Recall:', scores['test_recall_weighted'].mean())\n",
    "    print('Precision:', scores['test_precision_weighted'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score\n",
    "\n",
    "def crossVal(rfc, X, y):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#             'f1': make_scorer(f1_score, average='weighted'),\n",
    "#             'recall': make_scorer(recall_score, average='weighted')}\n",
    "\n",
    "    scoring = ['accuracy', 'f1_weighted', 'recall_weighted', 'precision_weighted']\n",
    "\n",
    "    # 使用交叉验证器对模型进行评估\n",
    "    scores = cross_validate(rfc, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "    # 输出交叉验证结果\n",
    "    print('Accuracy:', scores['test_accuracy'].mean())\n",
    "    print('F1 score:', scores['test_f1_weighted'].mean())\n",
    "    print('Recall:', scores['test_recall_weighted'].mean())\n",
    "    print('Precision:', scores['test_precision_weighted'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 定义随机森林分类器模型\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 定义交叉验证折数\n",
    "K = 5\n",
    "\n",
    "# 定义评估指标\n",
    "scoring = ['accuracy', 'f1_weighted', 'recall_weighted', 'precision_weighted']\n",
    "\n",
    "# 初始化评估指标结果列表\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# 分割数据为K个折\n",
    "data_folds = np.array_split(data, K)\n",
    "\n",
    "# 对每个折进行交叉验证\n",
    "for i in range(K):\n",
    "    # 将第i个折作为验证集，其余折作为训练集\n",
    "    data_train = np.concatenate(data_folds[:i] + data_folds[i+1:])\n",
    "    data_test = data_folds[i]\n",
    "\n",
    "    # 将训练数据和测试数据分开为X、y和labels\n",
    "    X_train = data_train[:, :-2]\n",
    "    y_train = data_train[:, -2]\n",
    "    labels_train = data_train[:, -1]\n",
    "    X_test = data_test[:, :-2]\n",
    "    y_test = data_test[:, -2]\n",
    "    labels_test = data_test[:, -1]\n",
    "\n",
    "    # 训练模型\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    # 预测标签\n",
    "    y_pred = rfc.predict(X_test)\n",
    "\n",
    "    # 计算评估指标\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# 输出交叉验证结果\n",
    "print('Accuracy:', np.mean(accuracy_scores))\n",
    "print('F1 score:', np.mean(f1_scores))\n",
    "print('Recall:', np.mean(recall_scores))\n",
    "print('Precision:', np.mean(precision_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      4\u001b[0m \u001b[39m# 假设X是形状为(n_samples, num_frames, num_features)的特征数组\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# 假设y是形状为(n_samples,)的标签数组\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# 假设batch_size是每个batch包含的视频数\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[39m# 获取数据的形状\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m n_samples, num_features \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X), \u001b[39mlen\u001b[39;49m(X[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     12\u001b[0m num_frames \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39m# 计算batch数\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 假设X是形状为(n_samples, num_frames, num_features)的特征数组\n",
    "# 假设y是形状为(n_samples,)的标签数组\n",
    "# 假设batch_size是每个batch包含的视频数\n",
    "# 假设num_classes是标签的类别数\n",
    "# 假设n_estimators是随机森林分类器的树数\n",
    "\n",
    "# 获取数据的形状\n",
    "n_samples, num_features = len(X), len(X[0][0])\n",
    "num_frames = 0\n",
    "\n",
    "\n",
    "# 计算batch数\n",
    "num_batches = n_samples // batch_size\n",
    "\n",
    "\n",
    "# 初始化分类器\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练分类器\n",
    "for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "    # 将数据打平为二维数组\n",
    "    X_flat = X_batch.reshape(-1, num_features)\n",
    "    y_flat = np.repeat(y_batch, num_frames)\n",
    "\n",
    "    # 训练分类器\n",
    "    rfc.fit(X_flat, y_flat)\n",
    "\n",
    "# 预测标签\n",
    "y_pred = []\n",
    "for X_batch in X_batches:\n",
    "    # 将数据打平为二维数组\n",
    "    X_flat = X_batch.reshape(-1, num_features)\n",
    "\n",
    "    # 预测标签\n",
    "    y_pred_batch = rfc.predict(X_flat)\n",
    "\n",
    "    # 将预测结果重新打包成三维数组\n",
    "    y_pred_batch = y_pred_batch.reshape(-1, num_frames)\n",
    "\n",
    "    # 对每个视频的预测结果取众数\n",
    "    y_pred_batch = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=y_pred_batch)\n",
    "\n",
    "    # 将预测结果添加到y_pred列表中\n",
    "    y_pred.append(y_pred_batch)\n",
    "\n",
    "# 将预测结果合并为一维数组\n",
    "y_pred = np.concatenate(y_pred)\n",
    "\n",
    "# 计算评\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.4036697247706422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.55      0.50      0.52        44\n",
      "           中       0.25      0.07      0.11        14\n",
      "           弱       0.27      0.60      0.37        20\n",
      "    没有回应（忽视）       0.45      0.29      0.35        31\n",
      "\n",
      "    accuracy                           0.40       109\n",
      "   macro avg       0.38      0.37      0.34       109\n",
      "weighted avg       0.43      0.40      0.39       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 使用随机森林预测一个frame\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_predict = rfc.predict(X_test)\n",
    "\n",
    "print(f\"acc:{rfc.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.431855249745158\n",
      "F1 score: 0.3939759228987903\n",
      "Recall: 0.431855249745158\n",
      "Precision: 0.4229085703859214\n"
     ]
    }
   ],
   "source": [
    "crossVal(rfc,X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video test\n",
    "import numpy as np\n",
    "\n",
    "# 假设idx是一个形状为(n_videos,)的数组，保存了每个视频中的第一个帧的索引\n",
    "# 假设y_pred和y_true分别是形状为(n_frames, n_classes)和形状为(n_videos,)的数组\n",
    "# 其中y_pred保存了每个帧的预测结果，y_true保存了每个视频的真实标签\n",
    "\n",
    "# 根据idx将y_pred的结果求和并取最大值作为视频级别的预测结果\n",
    "video_pred = []\n",
    "for i in idx:\n",
    "    # 获取当前视频的帧的数量\n",
    "    n_frames = np.sum(y_true == y_true[i])\n",
    "    # 将当前视频的帧的预测结果相加并取平均\n",
    "    video_result = np.mean(y_pred[i:i+n_frames], axis=0)\n",
    "    # 将平均结果中的最大值作为视频级别的预测结果\n",
    "    video_label = np.argmax(video_result)\n",
    "    video_pred.append(video_label)\n",
    "\n",
    "# 将y_true缩小到同样的数量，并与video_pred进行比较\n",
    "y_true_reduced = y_true[idx]\n",
    "accuracy = np.mean(y_true_reduced == video_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "强：5270, 中：2895, 弱：5147, 没有回应（忽视）：4361\n"
     ]
    }
   ],
   "source": [
    "print(f\"强：{len(y[y==0])}, 中：{len(y[y==1])}, 弱：{len(y[y==2])}, 没有回应（忽视）：{len(y[y==3])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17673"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frame2video_id)\n",
    "# len(y)\n",
    "# len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设X和y的形状分别为(n_frames, n_features)和(n_frames,)\n",
    "# frame2video_id是一个形状为(n_frames,)的列表，保存了每个frame属于的视频编号\n",
    "# 假设视频编号从1到N，其中N为视频数量\n",
    "\n",
    "\n",
    "\n",
    "# 首先将y和frame2video_id转换为数组\n",
    "y = np.array(y)\n",
    "frame2video_id = np.array(frame2video_id)\n",
    "\n",
    "print(N)\n",
    "\n",
    "# 构建一个空数组，用于保存每个视频的分类结果\n",
    "video_results = np.zeros((N, 4))\n",
    "\n",
    "# 遍历每个视频编号\n",
    "for i in range(1, N + 1):\n",
    "    # 找到属于当前视频编号的帧的索引\n",
    "    idx = np.where(frame2video_id == i)[0]\n",
    "    print(idx)\n",
    "    # 获取这些帧的分类结果\n",
    "    frames = y_predict[idx]\n",
    "    # 计算这些帧的平均分类结果\n",
    "    video_result = np.mean(frames, axis=0)\n",
    "    # 将平均分类结果保存到video_results数组中\n",
    "    video_results[i - 1] = video_result\n",
    "\n",
    "# 将video_results数组转换为整数编码的标签（即每个视频的类别）\n",
    "video_labels = np.argmax(video_results, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 建立决策树分类器\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_predict = clf.predict(X_test)\n",
    "\n",
    "# print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "# print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3160380564050289\n",
      "F1 score: 0.31868009277261755\n",
      "Recall: 0.3160380564050289\n",
      "Precision: 0.33386054629195855\n"
     ]
    }
   ],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 建立KNN分类器\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_predict = clf.predict(X_test)\n",
    "\n",
    "# print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "# print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30497791369351007\n",
      "F1 score: 0.2889542019589667\n",
      "Recall: 0.30497791369351007\n",
      "Precision: 0.3191428030283897\n"
     ]
    }
   ],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "结果很差 看warning原因应该是有一些结果直接没有分类  \n",
    "看看是否需要调参数或者直接去掉 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.4067892503536068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.39      0.59      0.47      1074\n",
      "           中       0.00      0.00      0.00       559\n",
      "           弱       0.41      0.35      0.38      1057\n",
      "    没有回应（忽视）       0.43      0.51      0.47       845\n",
      "\n",
      "    accuracy                           0.41      3535\n",
      "   macro avg       0.31      0.36      0.33      3535\n",
      "weighted avg       0.34      0.41      0.37      3535\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# clf = SVC(kernel='linear')\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3944954128440367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.60      0.41      0.49        44\n",
      "           中       0.20      0.07      0.11        14\n",
      "           弱       0.21      0.45      0.29        20\n",
      "    没有回应（忽视）       0.48      0.48      0.48        31\n",
      "\n",
      "    accuracy                           0.39       109\n",
      "   macro avg       0.37      0.35      0.34       109\n",
      "weighted avg       0.44      0.39      0.40       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# 定义模型参数\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 4,\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "# 将数据转换为DMatrix格式\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# 训练模型\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# 在测试集上预测\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41904519198097184\n",
      "F1 score: 0.4020817582525341\n",
      "Recall: 0.41904519198097184\n",
      "Precision: 0.414683914346187\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 定义xgboost分类器模型\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "crossVal(xgb,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM  \n",
    "not working so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 4) # 4 classes\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out, _ = self.lstm(x) # 1 * 100\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "        \n",
    "class mil_regression(nn.Module):\n",
    "    def __init__(self, input_size=786, hidden_size=100, num_layers=1, output_size=1):\n",
    "        ''' use LSTM for MIL '''\n",
    "        super(mil_regression, self).__init__()\n",
    "        self.net = LSTM(input_size, hidden_size, num_layers)\n",
    "        self.class_num = output_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input shape: (frame_num, feature_size)\n",
    "        \n",
    "\n",
    "        self.seg_num, self.feature_num = inputs.shape #\n",
    "\n",
    "        # outputs = torch.zeros((self.seg_num, self.class_num)).double.cuda() #  frame * 4（bool）\n",
    "\n",
    "        outputs = self.net(inputs)\n",
    "        # for i in range(self.seg_num):\n",
    "        #     outputs[i,:] = self.net(inputs[i]) # 786\n",
    "\n",
    "        # for idx, seg in enumerate(inputs):\n",
    "        #     seg = Variable(seg).cuda()\n",
    "        #     outputs[idx] = self.net(seg)\n",
    "\n",
    "        # 视频特征 = frame取平均\n",
    "        output = torch.mean(outputs, 1).cuda()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "model = mil_regression().cuda()\n",
    "\n",
    "epochs = 150\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X_train)): # 每次处理一个视频(对batch)\n",
    "\n",
    "        x = torch.tensor(X_train[i]).float().cuda()\n",
    "        y = torch.tensor(y_train[i]).float().cuda()\n",
    "        \n",
    "\n",
    "        if len(x.shape) ==1:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x)\n",
    "\n",
    "        single_loss = loss_function(y_pred, y)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if (i+1) % 10 == 0:\n",
    "        #     print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, len(X_train), single_loss.item()))\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(X_test)): # 每次处理一个视频(对batch)\n",
    "        x = torch.tensor(X_test[i]).float().cuda()\n",
    "        y = torch.tensor(y_test[i]).float().cuda()\n",
    "        print(y)\n",
    "\n",
    "        if len(x.shape) ==1:\n",
    "            continue\n",
    "\n",
    "        outputs = model(x)\n",
    "        print(outputs)\n",
    "        correct += (outputs == y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3. ,  3. ,  3. ],\n",
      "       [ 2. ,  3. , 48.5],\n",
      "       [ 0.5,  1.5, 47. ],\n",
      "       [ 0. ,  0. ,  0. ]]), array([[ 1. ,  1. ,  1. ],\n",
      "       [ 1. ,  1. ,  1. ],\n",
      "       [ 3. , 47.5, 92. ],\n",
      "       [ 3. , 47.5, 92. ]])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维矩阵\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [5, 8, 100],[5, 8, 100]])\n",
    "\n",
    "# 计算梯度\n",
    "dy = np.gradient(x)\n",
    "\n",
    "# 输出结果\n",
    "print(dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([nan, nan])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162420/1742590338.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  d2x.append(np.diff(dx2-dx1) / np.diff(dx3-dx2))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维数组\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算每一行相邻行之间的二阶导数\n",
    "d2x = []\n",
    "for i in range(1, x.shape[0]-1):\n",
    "    dx1 = np.gradient(x[i-1, :])\n",
    "    dx2 = np.gradient(x[i, :])\n",
    "    dx3 = np.gradient(x[i+1, :])\n",
    "    d2x.append(np.diff(dx2-dx1) / np.diff(dx3-dx2))\n",
    "\n",
    "# 输出结果\n",
    "print(d2x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 1.]), array([1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维数组\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算每一行数据对上一行数据的导数\n",
    "dx = []\n",
    "for i in range(1, x.shape[0]):\n",
    "    diff = np.diff(x[i, :]) / np.diff(x[i-1, :])\n",
    "    dx.append(diff)\n",
    "\n",
    "# 输出结果\n",
    "print(dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame  feature\n",
      "0      1      1.0\n",
      "1      2      3.0\n",
      "2      3      5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设df是一个DataFrame对象，其中包含frame和feature两列\n",
    "df = pd.DataFrame({'frame': [1, 3], 'feature': [1, 5]})\n",
    "\n",
    "# 将df的索引设置为frame列，并增加需要插值的索引值\n",
    "df = df.set_index('frame').reindex(range(df['frame'].min(), df['frame'].max()+1))\n",
    "\n",
    "# 对df进行插值\n",
    "df_interpolated = df.interpolate().reset_index()\n",
    "\n",
    "# 输出插值结果\n",
    "print(df_interpolated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

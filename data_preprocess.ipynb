{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要分别读入face和pose的数据并对应起来\n",
    "- 对于siblings_face 需要读入json  \n",
    "- 对于siblings_pose 需要读入csv    \n",
    "- 对于Label 需要读入csv\n",
    "\n",
    "\n",
    "*特别注意对于face，需要去除置信度小于阈值的数据  \n",
    "*要将video的label扩展到每个frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 读取标签文件\n",
    "label1 = pd.read_csv('labelA/回应情况-表格 1.csv')\n",
    "label2 = pd.read_csv('label_2/回应情况-表格 1.csv')\n",
    "\n",
    "label = pd.concat([label1, label2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('label_2/回应情况-表格 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing features\n",
    "\n",
    "missing =[\"19YS_20230318_03/VCAM_0017_1\", \"19YS_20230318_03/VCAM_0016\", \"19YS_20230318_03/VCAM_0016_1\"]\n",
    "\n",
    "for i in missing:\n",
    "    label = label[label['切片ID'] != i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>切片ID</th>\n",
       "      <th>回应情况</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>强</td>\n",
       "      <td>中</td>\n",
       "      <td>弱</td>\n",
       "      <td>没有回应（忽视）</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17YS_20230318_01/VCAM_0011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17YS_20230318_01/VCAM_0011_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17YS_20230318_01/VCAM_0011_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17YS_20230318_01/VCAM_0011_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           切片ID 回应情况 Unnamed: 2 Unnamed: 3 Unnamed: 4   \n",
       "0                           NaN    强          中          弱   没有回应（忽视）  \\\n",
       "1    17YS_20230318_01/VCAM_0011    0          0          1          0   \n",
       "2  17YS_20230318_01/VCAM_0011_1    0          0          1          0   \n",
       "3  17YS_20230318_01/VCAM_0011_2    0          0          1          0   \n",
       "4  17YS_20230318_01/VCAM_0011_3    0          0          1          0   \n",
       "\n",
       "   Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10   \n",
       "0         NaN         NaN         NaN         NaN         NaN          NaN  \\\n",
       "1         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "\n",
       "   Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15   \n",
       "0          NaN          NaN          NaN          NaN          NaN  \\\n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 16  Unnamed: 17  \n",
       "0          NaN          NaN  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3127, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.iloc[1,0][-4:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并读取face和pose特征  \n",
    "按照视频读取frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vel_and_acc(features):\n",
    "    \"\"\"\n",
    "    cal the mean and var of velocity and acceleration respectively of input features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_order_derivatives = np.gradient(features, axis=0)\n",
    "        second_order_derivatives = np.gradient(first_order_derivatives, axis=0)\n",
    "    except:\n",
    "        print(\"Error in get_vel_and_acc\")\n",
    "        print(features.shape)\n",
    "        print(print(f\"len:{len(face_df0)} and {len(face_df1)}\"))\n",
    "        print(max_fm)\n",
    "        print(\"------------------\")\n",
    "\n",
    "    # velecity\n",
    "    vel_means = np.mean(first_order_derivatives, axis=0)\n",
    "    vel_var = np.var(first_order_derivatives, axis=0)\n",
    "\n",
    "    # acceleration\n",
    "    acc_means = np.mean(second_order_derivatives, axis=0)\n",
    "    acc_var = np.var(second_order_derivatives, axis=0)\n",
    "    \n",
    "    return vel_means, vel_var, acc_means, acc_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[face error] in siblings_face_1024/VCAM_0011_22.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0011_29.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0011_103.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0011_144.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0010_8.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0010_29.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0010_55.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0010_108.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0010_112.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_14.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_17.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_19.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_24.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_31.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_32.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_35.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_39.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_40.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_41.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_42.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_43.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_44.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_76.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_95.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0009_101.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0008_51.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0008_98.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0008_158.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0008_159.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_12.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_13.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_27.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_30.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_32.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_33.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_45.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_69.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0015_74.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0014.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0014_154.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0013_9.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0013_86.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0013_88.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0013_96.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0013_146.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0013_154.csv: not enough frames\n",
      "[pose error] in siblings_face_1024/VCAM_0013_165.csv: not enough frames\n",
      "[pose error]: VCAM_0013_166_000000000000_keypoints.json not exist\n",
      "[pose error] in siblings_face_1024/VCAM_0013_166.csv: not enough frames\n",
      "[pose error]: VCAM_0013_167_000000000000_keypoints.json not exist\n",
      "[pose error] in siblings_face_1024/VCAM_0013_167.csv: not enough frames\n",
      "[pose error]: VCAM_0013_168_000000000000_keypoints.json not exist\n",
      "[pose error] in siblings_face_1024/VCAM_0013_168.csv: not enough frames\n",
      "[pose error]: VCAM_0013_169_000000000000_keypoints.json not exist\n",
      "[pose error] in siblings_face_1024/VCAM_0013_169.csv: not enough frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_469963/2515836036.py:170: RuntimeWarning: invalid value encountered in arccos\n",
      "  angles = np.arccos(cos_angles)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[face error] in siblings_face_1024/VCAM_0018_7.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0018_59.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0018_101.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0018_126.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0017_10.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0017_59.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0016_47.csv: not enough frames\n",
      "[pose error] in siblings_face_1024/VCAM_0020.csv: not enough frames\n",
      "[pose error]: VCAM_0020_1_000000000000_keypoints.json not exist\n",
      "[pose error] in siblings_face_1024/VCAM_0020_1.csv: not enough frames\n",
      "[pose error]: VCAM_0021_000000000000_keypoints.json not exist\n",
      "[pose error] in siblings_face_1024/VCAM_0021.csv: not enough frames\n",
      "[pose error]: VCAM_0021_1_000000000000_keypoints.json not exist\n",
      "[pose error] in siblings_face_1024/VCAM_0021_1.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0021_9.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0021_17.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0021_18.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0021_61.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0023_10.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0023_13.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0023_25.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0023_30.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0023_48.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0024_136.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0024_137.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0025_21.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0027_11.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0027_28.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0027_48.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0027_73.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0027_137.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0027_139.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0027_161.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0027_165.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0028_41.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0028_42.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0028_43.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0028_55.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0028_57.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0028_58.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0028_59.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0028_122.csv: not enough frames\n",
      "[face error] in siblings_face_1024/VCAM_0029_121.csv: not enough frames\n",
      "Total face feat:936507, pose feat:192635\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 332\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal face feat:\u001b[39m\u001b[39m{\u001b[39;00mface_count\u001b[39m}\u001b[39;00m\u001b[39m, pose feat:\u001b[39m\u001b[39m{\u001b[39;00mpose_count\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    331\u001b[0m \u001b[39m# 读入的数量\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRead in videos X:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(X)\u001b[39m}\u001b[39;00m\u001b[39m, face_feat:\u001b[39m\u001b[39m{\u001b[39;00mrface_count\u001b[39m}\u001b[39;00m\u001b[39m,pose_feat:\u001b[39m\u001b[39m{\u001b[39;00mrpose_count\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[39m# # drop\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDrop \u001b[39m\u001b[39m{\u001b[39;00mface_count\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mrface_count\u001b[39m}\u001b[39;00m\u001b[39m face features, \u001b[39m\u001b[39m{\u001b[39;00mpose_count\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mrpose_count\u001b[39m}\u001b[39;00m\u001b[39m pose features\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# set openface confidence threshold\n",
    "confidence_threshold = 0.1\n",
    "\n",
    "# 导入特征并对齐标签\n",
    "low_video_features = []\n",
    "high_video_features = []\n",
    "video_labels = []\n",
    "labels = []\n",
    "frame2video_id = [] # 记录frame属于哪个video\n",
    "# 记录原本有多少条记录\n",
    "face_count = 0\n",
    "pose_count = 0\n",
    "# 记录读入的记录\n",
    "rface_count = 0\n",
    "rpose_count = 0\n",
    "\n",
    "# for each video\n",
    "for i in range(1,len(label)):\n",
    "    directory = label.iloc[i, 0]\n",
    "    frame_features = []\n",
    "    try:\n",
    "        # VCAM number\n",
    "        Date = directory.split('/')[0] # 15YS_20230317_01\n",
    "        Vcam = directory.split('/')[-1]  # VCAM_xxxx_xx\n",
    "        VcamID = Vcam.split('_')[1] # xxxx\n",
    "\n",
    "        # reconstruct the correct Openpose directory\n",
    "        video_directory = os.path.join('siblings_pose', Date,'VCAM_'+VcamID, Vcam)\n",
    "        json_directory = os.path.join(video_directory, 'json')\n",
    "    except:\n",
    "        print(f\"[load error]:{directory}\")\n",
    "\n",
    "    json_files = os.listdir(json_directory)\n",
    "    json_files.sort(key=lambda x: int(x.split('_')[2])) # sort by the frame id\n",
    "    \n",
    "\n",
    "    # the correct Openface csv file\n",
    "    # feature_file = os.path.join('siblings_face', directory + '.csv')\n",
    "    feature_file = os.path.join('siblings_face_1024', Vcam + '.csv')\n",
    "\n",
    "\n",
    "    # the label data for this video\n",
    "    label_value = label.iloc[i, 1:5] # 取1-4位的标签\n",
    "    video_id = i # video id\n",
    "\n",
    "    # Load face data of a video\n",
    "    try:\n",
    "        face_csv_data = pd.read_csv(feature_file)\n",
    "    except:\n",
    "        print(f\"[face error]: {feature_file} not exist\")\n",
    "        continue\n",
    "    \n",
    "    # log the num of face data rows\n",
    "    face_count += face_csv_data.shape[0]\n",
    "\n",
    "    # 丢弃置信度小于0.5的数据\n",
    "    face_csv_data = face_csv_data[face_csv_data['confidence'] >= confidence_threshold]\n",
    "\n",
    "    # TODO 丢弃 success = 0 的数据\n",
    "    face_csv_data = face_csv_data[face_csv_data['success'] ==1]\n",
    "\n",
    "    # 找到frame中有多于2个不同face_id的帧\n",
    "    counts = face_csv_data.groupby('frame')['face_id'].nunique()\n",
    "    frames_to_drop = counts[counts > 2].index.tolist()\n",
    "\n",
    "    \n",
    "    # 对于每个需要处理的帧，删除置信度最低的行，直到只剩下2个face_id\n",
    "    for frame in frames_to_drop:\n",
    "        frame_df = face_csv_data[face_csv_data['frame'] == frame]\n",
    "        while frame_df['face_id'].nunique() > 2:\n",
    "            min_confidence = frame_df['confidence'].min()\n",
    "            rows_to_drop = frame_df[(frame_df['confidence'] == min_confidence)]['face_id'].tolist()\n",
    "            frame_df = frame_df[~frame_df['face_id'].isin(rows_to_drop)]\n",
    "        face_csv_data = face_csv_data[face_csv_data['frame'] != frame]\n",
    "        face_csv_data = pd.concat([face_csv_data, frame_df], ignore_index=True)\n",
    "\n",
    "    # 丢弃只有1个face_id的帧 \n",
    "    # TODO 是否可以不丢弃？\n",
    "    face_csv_data = face_csv_data.groupby('frame').filter(lambda x: len(x) == 2)\n",
    "\n",
    "\n",
    "    # 按照frame分组，并根据x_30(nose x位置)的大小对face_id进行赋值 x较小标记为0\n",
    "    def assign_face_id(group):\n",
    "        if len(group) != 2:\n",
    "            return None\n",
    "        else:\n",
    "            if group['x_30'].iloc[0] < group['x_30'].iloc[1]:\n",
    "                group['face_id'] = [0, 1]\n",
    "            else:\n",
    "                group['face_id'] = [1, 0]\n",
    "            return group\n",
    "\n",
    "    face_csv_data = face_csv_data.groupby('frame').apply(assign_face_id).reset_index(drop=True)\n",
    "    # # 重新排序\n",
    "    # face_csv_data= face_csv_data.set_index(['face_id', 'frame'])\n",
    "\n",
    "    # def sort_by_frame(group):\n",
    "    #     return group.sort_values(by='frame')\n",
    "\n",
    "    # face_csv_data = face_csv_data.groupby('face_id').apply(sort_by_frame)\n",
    "\n",
    "\n",
    "    # 将df根据face_id列分成两个DataFrame对象\n",
    "    face_df0 = face_csv_data[face_csv_data['face_id'] == 0]\n",
    "    face_df1 = face_csv_data[face_csv_data['face_id'] == 1]\n",
    "\n",
    "    # 按照frame_id列进行排序\n",
    "    # face_df0 = face_df0.sort_values(by='frame')\n",
    "    # face_df1 = face_df1.sort_values(by='frame')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 将df的索引设置为frame_id,并且插值\n",
    "    try:\n",
    "        min_fm, max_fm = face_df0['frame'].min(), face_df0['frame'].max()\n",
    "        if(max_fm - min_fm >2):\n",
    "            # 记录contribute 数据数量\n",
    "            rface_count += 2*face_df0.shape[0]\n",
    "            # 插值\n",
    "            face_df0 = face_df0.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "            face_df1 = face_df1.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "        else:\n",
    "            print(f\"[face error] in {feature_file}: not enough frames\")\n",
    "            # print(f\"len:{len(face_df0)} and {len(face_df1)}\")\n",
    "            continue\n",
    "    except:\n",
    "        print(f\"[face error] in {feature_file}:unknown error in interpolation and reindex\")\n",
    "        continue\n",
    "    # # 对df进行插值\n",
    "    #  face_df0.reset_index()\n",
    "    \n",
    "    ###############  face low feature #######################\n",
    "    # low level feat to cal vel and acc\n",
    "    face_low_feat = ['pose_Tx', 'pose_Ty', 'pose_Tz','pose_Rx', 'pose_Ry', 'pose_Rz', 'gaze_angle_x', 'gaze_angle_y']\n",
    "    au_feat = ['AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU15_r',  'AU20_r', 'AU23_r', 'AU26_r']\n",
    "    \n",
    "\n",
    "    # 每个人的low feat 的 vel and acc\n",
    "    v_mean_0, v_var_0, a_mean_0, a_var_0 = get_vel_and_acc(face_df0[face_low_feat])\n",
    "    v_mean_1, v_var_1, a_mean_1, a_var_1 = get_vel_and_acc(face_df1[face_low_feat])\n",
    "    au_mean_0 = np.array(face_df0[au_feat].mean())\n",
    "    au_mean_1 = np.array(face_df1[au_feat].mean())  \n",
    "    au_var_0 = np.array(face_df0[au_feat].var())\n",
    "    au_var_1 = np.array(face_df1[au_feat].var())\n",
    "\n",
    "\n",
    "    # 每一frame的 face feature\n",
    "    # features_face = face_csv_data.values \n",
    "    low_features_face_0 = np.concatenate((v_mean_0, v_var_0, a_mean_0, a_var_0,au_mean_0,au_var_0))\n",
    "    low_features_face_1 = np.concatenate((v_mean_1, v_var_1, a_mean_1, a_var_1,au_mean_1,au_var_1))\n",
    "\n",
    "    ###############  face high feature #######################\n",
    "\n",
    "    # @1 gaze_angle -> indicating gaze direction\n",
    "    gaze_angle_0 = np.array(face_df0[['gaze_angle_x','gaze_angle_y']])\n",
    "    gaze_angle_1 = np.array(face_df1[['gaze_angle_x','gaze_angle_y']])\n",
    "\n",
    "    gaze_mean_0 = gaze_angle_0.mean(axis=0)\n",
    "    gaze_mean_1 = gaze_angle_1.mean(axis=0) \n",
    "    gaze_var_0 = gaze_angle_0.var(axis=0)\n",
    "    gaze_var_1 = gaze_angle_0.var(axis=0)\n",
    "\n",
    "\n",
    "    # @2 计算两个人之间的角度夹角\n",
    "    # gaze_diff_x = face_df0['gaze_angle_x'] - face_df1['gaze_angle_x']\n",
    "    # gaze_diff_y = face_df0['gaze_angle_y'] - face_df1['gaze_angle_y']\n",
    "\n",
    "    cos_angles = np.sum(gaze_angle_0 * gaze_angle_1, axis=1) / (np.linalg.norm(gaze_angle_0, axis=1) * np.linalg.norm(gaze_angle_1, axis=1))\n",
    "    angles = np.arccos(cos_angles)\n",
    "    # 将弧度值转换为角度值\n",
    "    gaze_angles = np.degrees(angles)\n",
    "\n",
    "    gaze_angle_mean = gaze_angles.mean(axis=0)\n",
    "    gaze_angle_var = gaze_angles.var(axis=0) \n",
    "    v_mean_ga, v_var_ga, a_mean_ga, a_var_ga = get_vel_and_acc(gaze_angles)\n",
    "    # 单个数值合并成 array\n",
    "    gaze_feat = np.array([gaze_angle_mean, gaze_angle_var, v_mean_ga, v_var_ga, a_mean_ga, a_var_ga])\n",
    "\n",
    "\n",
    "    # @3 Motion synchronization -> abs\n",
    "    v_mean_ms, v_var_ms, a_mean_ms, a_var_ms = get_vel_and_acc((face_df0[face_low_feat] - face_df1[face_low_feat]).abs())\n",
    "\n",
    "\n",
    "    # 每一frame的 face feature\n",
    "    # features_face = face_csv_data.values \n",
    "    high_features_face = np.concatenate((gaze_mean_0, gaze_mean_1, gaze_var_0, gaze_var_1, \\\n",
    "                                         gaze_feat,\n",
    "                                         v_mean_ms, v_var_ms, a_mean_ms, a_var_ms\n",
    "                                        ))\n",
    "\n",
    "\n",
    "    ###############  pose feature #######################\n",
    "    \n",
    "    \n",
    "    pose_json_data = [] # save all frame data\n",
    "\n",
    "    # feature names in 'pose_keypoints_2d' in json file\n",
    "    col_name = [\n",
    "        'frame','face_id',\n",
    "       'x0', 'y0', 'c0', 'x1', 'y1', 'c1', 'x2', 'y2', 'c2', 'x3', 'y3', 'c3', 'x4', 'y4', 'c4',\n",
    "       'x5', 'y5', 'c5', 'x6', 'y6', 'c6', 'x7', 'y7', 'c7', 'x8', 'y8', 'c8',\n",
    "       'x9', 'y9', 'c9', 'x10', 'y10', 'c10', 'x11', 'y11', 'c11', 'x12', 'y12', 'c12',\n",
    "       'x13', 'y13', 'c13', 'x14', 'y14', 'c14', 'x15', 'y15', 'c15', 'x16', 'y16', 'c16', \n",
    "       'x17', 'y17', 'c17', 'x18', 'y18', 'c18', 'x19', 'y19', 'c19', 'x20', 'y20', 'c20', \n",
    "       'x21', 'y21', 'c21', 'x22', 'y22', 'c22', 'x23', 'y23', 'c23', 'x24', 'y24', 'c24'\n",
    "       ]\n",
    "\n",
    "    # 创建空的 dataframe\n",
    "    pose_df0 = pd.DataFrame(columns=col_name)\n",
    "    pose_df1 = pd.DataFrame(columns=col_name)\n",
    "    \n",
    "    \n",
    "    # Load pose data of a video frame\n",
    "    for file in json_files: # for a single frame\n",
    "        file_path = os.path.join(json_directory, file)\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "        except:\n",
    "            print(f\"[pose error]: {file} not exist\")\n",
    "            continue\n",
    "\n",
    "        # log the number\n",
    "        pose_count += len(data['people'])\n",
    "        \n",
    "        # 漏检测 只有1人的情况\n",
    "        if len(data['people']) != 2:\n",
    "            # drop this frame\n",
    "            continue\n",
    "        \n",
    "        row0 = data['people'][0]['pose_keypoints_2d'] # x0,y0,c0,x1,y1,c1,... x24,y24,c24\n",
    "        row1 = data['people'][1]['pose_keypoints_2d']\n",
    "\n",
    "        # face_id对应 x较小 标记为0，x较大 标记为1 \n",
    "        if(row0[0]>row1[0]):\n",
    "            row0,row1 = row1,row0 # swap\n",
    "\n",
    "        # 插入face_id\n",
    "        # TODO del face_id no need anymore\n",
    "        row0.insert(0,0)\n",
    "        row1.insert(0,1)\n",
    "\n",
    "        # 插入frame\n",
    "        frame_id = int(file.split('_')[-2]) # 文件 frame_id\n",
    "\n",
    "        # 去掉多余的最后一 frame 文件 否者会导致 frame 重复\n",
    "        if frame_id % 5 != 0:\n",
    "            continue\n",
    "\n",
    "        frame_id = frame_id // 5 + 1 # 恢复frame id 抽帧后的 id\n",
    "        row0.insert(0,frame_id)\n",
    "        row1.insert(0,frame_id)\n",
    "\n",
    "        pose_df0.loc[len(pose_df0)] = row0\n",
    "        pose_df1.loc[len(pose_df1)] = row1\n",
    "\n",
    "     # 将df的索引设置为frame_id,并且插值\n",
    "    try:\n",
    "        # set frame to int type\n",
    "        pose_df0['frame'] = pose_df0['frame'].astype(int)\n",
    "        pose_df1['frame'] = pose_df1['frame'].astype(int)\n",
    "        min_fm, max_fm = pose_df0['frame'].min(), pose_df0['frame'].max()\n",
    "\n",
    "        if(max_fm - min_fm >2):\n",
    "            # 记录contribute 数据数量\n",
    "            rpose_count += 2*pose_df0.shape[0]\n",
    "            # 插值\n",
    "            pose_df0 = pose_df0.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "            pose_df1 = pose_df1.set_index('frame').reindex(range(min_fm, max_fm+1)).interpolate()\n",
    "        else:\n",
    "            print(f\"[pose error] in {feature_file}: not enough frames\")\n",
    "            # print(f\"len:{len(face_df0)} and {len(face_df1)}\")\n",
    "            continue\n",
    "    except:\n",
    "        print(f\"[pose error] in {feature_file}:unknown error in interpolation and reindex\")\n",
    "        continue\n",
    "\n",
    "    ###############  pose low feature #######################\n",
    "    \n",
    "    # TODO select low feat\n",
    "    # pose_low_feat = ['x','y']\n",
    "    pose_low_feat = col_name[2:]\n",
    "    pose_low_feat = [col for col in pose_low_feat if not col.startswith('c')] # filter all confidence\n",
    "\n",
    "    # 每个人的low feat 的 vel and acc\n",
    "    v_mean_0, v_var_0, a_mean_0, a_var_0 = get_vel_and_acc(pose_df0[pose_low_feat])\n",
    "    v_mean_1, v_var_1, a_mean_1, a_var_1 = get_vel_and_acc(pose_df1[pose_low_feat])\n",
    "    mean_0 = np.array(pose_df0[pose_low_feat].mean())\n",
    "    mean_1 = np.array(pose_df1[pose_low_feat].mean())\n",
    "    var_0 = np.array(pose_df0[pose_low_feat].var())\n",
    "    var_1 = np.array(pose_df1[pose_low_feat].var())\n",
    "    \n",
    "\n",
    "    ###############  pose high feature #######################\n",
    "    # TODO pose high feature\n",
    "\n",
    "    # # @1 left and right shoulder distance vel → (mean + var) = 2\n",
    "    # shoulder_lf_diff_0 = (pose_df0[['x2','y2']] - pose_df0[['x5','y5']]).abs()\n",
    "    # shoulder_lf_diff_1 = (pose_df1[['x2','y2']] - pose_df1[['x5','y5']]).abs()\n",
    "\n",
    "    # v_mean_lrs, v_var_lrs, a_mean_lrs, a_var_lrs = get_vel_and_acc(np.concatenate(shoulder_lf_diff_0,shoulder_lf_diff_1))\n",
    "\n",
    "    # # @2 质心靠近程度\n",
    "    # centroid_diff_x = np.abs(mean_0[0:-1:2].mean() - mean_1[0:-1:2].mean()) # 所有 x 平均(单数 index)\n",
    "    # centroid_diff_y = np.abs(mean_0[1:-1:2].mean() - mean_1[1:-1:2].mean()) # 所有 y 平均(双数 index)\n",
    "\n",
    "\n",
    "    # features_pose = np.array(pose_json_data)\n",
    "    low_features_pose_0 = np.concatenate((v_mean_0, v_var_0, a_mean_0, a_var_0,mean_0,var_0))\n",
    "    low_features_pose_1 = np.concatenate((v_mean_1, v_var_1, a_mean_1, a_var_1,mean_1,var_1))\n",
    "\n",
    "    # 将记录视频特征\n",
    "    low_video_features.append(np.concatenate((low_features_face_0, low_features_pose_0, low_features_face_1, low_features_pose_1))) # simply attach them all together\n",
    "    high_video_features.append(np.concatenate((high_features_face, low_features_face_0, low_features_pose_0, low_features_face_1, low_features_pose_1)))\n",
    "\n",
    "\n",
    "    # video 级别label\n",
    "    video_labels.append(np.argmax(label_value.astype(\"int\"),axis=0)) # one-hot to class id\n",
    "    \n",
    "    # # frame级别label\n",
    "    # video_labels.append(np.array(labels))\n",
    "\n",
    "X_low = low_video_features\n",
    "X_high = high_video_features\n",
    "\n",
    "y = video_labels\n",
    "\n",
    "\n",
    "# 总共遍历的face特征和pose特征数\n",
    "print(f\"Total face feat:{face_count}, pose feat:{pose_count}\")\n",
    "# 读入的数量\n",
    "print(f\"Read in videos X:{len(X_low)}, face_feat:{rface_count},pose_feat:{rpose_count}\")\n",
    "# # drop\n",
    "print(f\"Drop {face_count - rface_count} face features, {pose_count - rpose_count} pose features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total face feat:936507, pose feat:192635\n",
      "Read in videos X:3032, face_feat:694744,pose_feat:191272\n",
      "Drop 241763 face features, 1363 pose features\n"
     ]
    }
   ],
   "source": [
    "# 总共遍历的face特征和pose特征数\n",
    "print(f\"Total face feat:{face_count}, pose feat:{pose_count}\")\n",
    "# 读入的数量\n",
    "print(f\"Read in videos X:{len(X_low)}, face_feat:{rface_count},pose_feat:{rpose_count}\")\n",
    "# # drop\n",
    "print(f\"Drop {face_count - rface_count} face features, {pose_count - rpose_count} pose features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = high_video_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = np.apply_along_axis(lambda x: x / np.linalg.norm(x), axis=0, arr=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in videos y:3032\n"
     ]
    }
   ],
   "source": [
    "print(f\"Read in videos y:{len(y)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:746\n"
     ]
    }
   ],
   "source": [
    "print(f\"X:{len(X[0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查 nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([940]),)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(X).any(axis=1)==True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video num: X_train:2425, X_test:607, y_train:2425, y_test:607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# frame split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, random_state=42)\n",
    "print(f\"Video num: X_train:{len(X_train)}, X_test:{len(X_test)}, y_train:{len(y_train)}, y_test:{len(y_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation  \n",
    "- 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score\n",
    "\n",
    "def crossVal(rfc, X, y):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#             'f1': make_scorer(f1_score, average='weighted'),\n",
    "#             'recall': make_scorer(recall_score, average='weighted')}\n",
    "\n",
    "    scoring = ['accuracy', 'f1_weighted', 'recall_weighted', 'precision_weighted']\n",
    "\n",
    "    # 使用交叉验证器对模型进行评估\n",
    "    scores = cross_validate(rfc, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "    # 输出交叉验证结果\n",
    "    print('Accuracy:', scores['test_accuracy'].mean())\n",
    "    print('F1 score:', scores['test_f1_weighted'].mean())\n",
    "    print('Recall:', scores['test_recall_weighted'].mean())\n",
    "    print('Precision:', scores['test_precision_weighted'].mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# 使用随机森林预测一个frame\u001b[39;00m\n\u001b[1;32m      6\u001b[0m rfc \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m rfc\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      8\u001b[0m y_predict \u001b[39m=\u001b[39m rfc\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39macc:\u001b[39m\u001b[39m{\u001b[39;00mrfc\u001b[39m.\u001b[39mscore(X_test,\u001b[39m \u001b[39my_test)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    346\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 使用随机森林预测一个frame\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_predict = rfc.predict(X_test)\n",
    "\n",
    "print(f\"acc:{rfc.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: nan\n",
      "F1 score: nan\n",
      "Recall: nan\n",
      "Precision: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 76, in _cached_call\n",
      "    return cache[method]\n",
      "KeyError: 'predict'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 78, in _cached_call\n",
      "    result = getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/base.py\", line 565, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "crossVal(rfc,X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"强：{len(y[y==0])}, 中：{len(y[y==1])}, 弱：{len(y[y==2])}, 没有回应（忽视）：{len(y[y==3])}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 建立决策树分类器\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_predict = clf.predict(X_test)\n",
    "\n",
    "# print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "# print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35907096774193553\n",
      "F1 score: 0.3549327998522269\n",
      "Recall: 0.35907096774193553\n",
      "Precision: 0.3589581231396566\n"
     ]
    }
   ],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 建立KNN分类器\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_predict = clf.predict(X_test)\n",
    "\n",
    "# print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "# print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3189032258064516\n",
      "F1 score: 0.3065399857800289\n",
      "Recall: 0.3189032258064516\n",
      "Precision: 0.3245333584546152\n"
     ]
    }
   ],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "结果很差 看warning原因应该是有一些结果直接没有分类  \n",
    "看看是否需要调参数或者直接去掉 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.40      0.62      0.48        39\n",
      "           中       0.00      0.00      0.00        19\n",
      "           弱       0.43      0.32      0.36        38\n",
      "    没有回应（忽视）       0.43      0.55      0.48        29\n",
      "\n",
      "    accuracy                           0.42       125\n",
      "   macro avg       0.32      0.37      0.33       125\n",
      "weighted avg       0.36      0.42      0.37       125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# clf = SVC(kernel='linear')\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "print(f\"acc:{clf.score(X_test, y_test)}\")\n",
    "print(classification_report(y_test, y_predict, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3733161290322581\n",
      "F1 score: 0.3331413623531893\n",
      "Recall: 0.3733161290322581\n",
      "Precision: 0.31028633793320354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansonlo/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "crossVal(clf,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           强       0.51      0.62      0.56        39\n",
      "           中       0.17      0.05      0.08        19\n",
      "           弱       0.47      0.53      0.49        38\n",
      "    没有回应（忽视）       0.52      0.52      0.52        29\n",
      "\n",
      "    accuracy                           0.48       125\n",
      "   macro avg       0.41      0.43      0.41       125\n",
      "weighted avg       0.45      0.48      0.46       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# 定义模型参数\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 4,\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "# 将数据转换为DMatrix格式\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# 训练模型\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# 在测试集上预测\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"强\",\"中\",\"弱\",\"没有回应（忽视）\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.432658064516129\n",
      "F1 score: 0.40997846722685444\n",
      "Recall: 0.432658064516129\n",
      "Precision: 0.41474823524613236\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 定义xgboost分类器模型\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "crossVal(xgb,X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM  \n",
    "not working so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 4) # 4 classes\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out, _ = self.lstm(x) # 1 * 100\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "        \n",
    "class mil_regression(nn.Module):\n",
    "    def __init__(self, input_size=786, hidden_size=100, num_layers=1, output_size=1):\n",
    "        ''' use LSTM for MIL '''\n",
    "        super(mil_regression, self).__init__()\n",
    "        self.net = LSTM(input_size, hidden_size, num_layers)\n",
    "        self.class_num = output_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input shape: (frame_num, feature_size)\n",
    "        \n",
    "\n",
    "        self.seg_num, self.feature_num = inputs.shape #\n",
    "\n",
    "        # outputs = torch.zeros((self.seg_num, self.class_num)).double.cuda() #  frame * 4（bool）\n",
    "\n",
    "        outputs = self.net(inputs)\n",
    "        # for i in range(self.seg_num):\n",
    "        #     outputs[i,:] = self.net(inputs[i]) # 786\n",
    "\n",
    "        # for idx, seg in enumerate(inputs):\n",
    "        #     seg = Variable(seg).cuda()\n",
    "        #     outputs[idx] = self.net(seg)\n",
    "\n",
    "        # 视频特征 = frame取平均\n",
    "        output = torch.mean(outputs, 1).cuda()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "model = mil_regression().cuda()\n",
    "\n",
    "epochs = 150\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X_train)): # 每次处理一个视频(对batch)\n",
    "\n",
    "        x = torch.tensor(X_train[i]).float().cuda()\n",
    "        y = torch.tensor(y_train[i]).float().cuda()\n",
    "        \n",
    "\n",
    "        if len(x.shape) ==1:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x)\n",
    "\n",
    "        single_loss = loss_function(y_pred, y)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if (i+1) % 10 == 0:\n",
    "        #     print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, len(X_train), single_loss.item()))\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(X_test)): # 每次处理一个视频(对batch)\n",
    "        x = torch.tensor(X_test[i]).float().cuda()\n",
    "        y = torch.tensor(y_test[i]).float().cuda()\n",
    "        print(y)\n",
    "\n",
    "        if len(x.shape) ==1:\n",
    "            continue\n",
    "\n",
    "        outputs = model(x)\n",
    "        print(outputs)\n",
    "        correct += (outputs == y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3. ,  3. ,  3. ],\n",
      "       [ 2. ,  3. , 48.5],\n",
      "       [ 0.5,  1.5, 47. ],\n",
      "       [ 0. ,  0. ,  0. ]]), array([[ 1. ,  1. ,  1. ],\n",
      "       [ 1. ,  1. ,  1. ],\n",
      "       [ 3. , 47.5, 92. ],\n",
      "       [ 3. , 47.5, 92. ]])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维矩阵\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [5, 8, 100],[5, 8, 100]])\n",
    "\n",
    "# 计算梯度\n",
    "dy = np.gradient(x)\n",
    "\n",
    "# 输出结果\n",
    "print(dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([nan, nan])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162420/1742590338.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  d2x.append(np.diff(dx2-dx1) / np.diff(dx3-dx2))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维数组\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算每一行相邻行之间的二阶导数\n",
    "d2x = []\n",
    "for i in range(1, x.shape[0]-1):\n",
    "    dx1 = np.gradient(x[i-1, :])\n",
    "    dx2 = np.gradient(x[i, :])\n",
    "    dx3 = np.gradient(x[i+1, :])\n",
    "    d2x.append(np.diff(dx2-dx1) / np.diff(dx3-dx2))\n",
    "\n",
    "# 输出结果\n",
    "print(d2x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 1.]), array([1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个二维数组\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算每一行数据对上一行数据的导数\n",
    "dx = []\n",
    "for i in range(1, x.shape[0]):\n",
    "    diff = np.diff(x[i, :]) / np.diff(x[i-1, :])\n",
    "    dx.append(diff)\n",
    "\n",
    "# 输出结果\n",
    "print(dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame  feature\n",
      "0      1      1.0\n",
      "1      2      3.0\n",
      "2      3      5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设df是一个DataFrame对象，其中包含frame和feature两列\n",
    "df = pd.DataFrame({'frame': [1, 3], 'feature': [1, 5]})\n",
    "\n",
    "# 将df的索引设置为frame列，并增加需要插值的索引值\n",
    "df = df.set_index('frame').reindex(range(df['frame'].min(), df['frame'].max()+1))\n",
    "\n",
    "# 对df进行插值\n",
    "df_interpolated = df.interpolate().reset_index()\n",
    "\n",
    "# 输出插值结果\n",
    "print(df_interpolated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1de83ba939c2ac04c4cd5f42769ee29bf75010bc15e3148e0552f0994dd76a71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
